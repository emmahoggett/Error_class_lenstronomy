{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "significant-montreal",
   "metadata": {
    "id": "written-sample"
   },
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "handled-terror",
   "metadata": {
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1616692453475,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "comfortable-tucson"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from helpers import*\n",
    "from lenshelpers import*\n",
    "\n",
    "from model.baseline import*\n",
    "from model.densenet import*\n",
    "from model.alexnet import*\n",
    "from model.resnet18 import*\n",
    "from model.vgg16 import*\n",
    "from model.googLeNet import*\n",
    "from model.squeezeNet import*\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-marathon",
   "metadata": {
    "id": "enhanced-enterprise"
   },
   "source": [
    "# 1. Building the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fallen-pierce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 5231,
     "status": "error",
     "timestamp": 1616692454742,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "intermediate-blood",
    "outputId": "c1d905f2-e341-4469-ac08-4f56582db157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation Finished\n"
     ]
    }
   ],
   "source": [
    "# Build the four classes \n",
    "config_repo_model = 'data/configFile/config_model'\n",
    "\n",
    "size = 500\n",
    "for i in np.arange(1,4):\n",
    "    #model_name = config_repo_model + str(i) + '.yaml'\n",
    "    res = Residual(size)\n",
    "    res.build(i)\n",
    "\n",
    "print('Data Generation Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conventional-retention",
   "metadata": {
    "executionInfo": {
     "elapsed": 5206,
     "status": "aborted",
     "timestamp": 1616692454724,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "j4ngxjJlpBa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data Finished\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.DataFrame()\n",
    "for i in np.arange(1,4):\n",
    "    [img, meta] = read_hdf5(i, path = \"data/dataSet/\")\n",
    "    metadata = pd.concat([metadata,meta], ignore_index=True)\n",
    "    if i == 1:\n",
    "        final_array = img\n",
    "    else:\n",
    "         final_array = np.concatenate((final_array, img))\n",
    "metadata ['ID'] = np.arange(0,final_array.shape[0])\n",
    "data_set = CombineDataset(metadata,'ID','class',final_array)\n",
    "\n",
    "print('Reading Data Finished')\n",
    "data_train, data_test = train_test_split(data_set,train_size=0.9,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-chapter",
   "metadata": {
    "executionInfo": {
     "elapsed": 5201,
     "status": "aborted",
     "timestamp": 1616692454725,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "UkL0TbTeB092"
   },
   "outputs": [],
   "source": [
    "batch_size_train = 50\n",
    "batch_size_test = 10\n",
    "max_epoch = 10\n",
    "\n",
    "\n",
    "loader_train = DataLoader(data_train, batch_size = batch_size_train, shuffle = True, \n",
    "                          num_workers = 0, drop_last=True)\n",
    "\n",
    "loader_test = DataLoader(data_test, batch_size = batch_size_test, shuffle = True, \n",
    "                         num_workers = 0, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-russian",
   "metadata": {
    "id": "behind-benchmark"
   },
   "source": [
    "# 2. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-loading",
   "metadata": {
    "id": "jRnYdliz-86r"
   },
   "source": [
    "## 2.1. Residual network\n",
    "\n",
    "**Results** : 6 epochs - 0.993 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excited-scoop",
   "metadata": {
    "executionInfo": {
     "elapsed": 5195,
     "status": "aborted",
     "timestamp": 1616692454725,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "Epv5bSQ8_2v6"
   },
   "outputs": [],
   "source": [
    "net = CNNNetBasic()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "czech-witch",
   "metadata": {
    "executionInfo": {
     "elapsed": 5190,
     "status": "aborted",
     "timestamp": 1616692454726,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "6jdGxSbwAkOV"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-05bead943a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmean_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader_train' is not defined"
     ]
    }
   ],
   "source": [
    "test_acc = np.zeros(max_epoch)\n",
    "# Optimal number of epochs : 6 epochs - 0.993 accuracy\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    train_net(loader_train, net, optimizer, criterion, epoch)\n",
    "    mean_accuracy = test_net(loader_test,net)\n",
    "    test_acc[epoch] = mean_accuracy\n",
    "\n",
    "    print(\"epoch: {:.3f}, accuracy: {:.3f} \".format(epoch, mean_accuracy))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-diversity",
   "metadata": {
    "executionInfo": {
     "elapsed": 5185,
     "status": "aborted",
     "timestamp": 1616692454727,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "9chu_f9-Ao6m"
   },
   "outputs": [],
   "source": [
    "f1_samples = 0\n",
    "accuracy = 0\n",
    "iteration = 0\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    for data in loader_test:\n",
    "        images, meta_img, labels = data\n",
    "        outputs = net(images)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "        f1_samples+=result['samples/f1']\n",
    "        accuracy+=result['samples/recall']\n",
    "        iteration+=1\n",
    "\n",
    "\n",
    "mean_f1 = f1_samples/(iteration+1)\n",
    "mean_accuracy =accuracy/(iteration+1)\n",
    "\n",
    "print(\"accuracy: {:.3f} \"\n",
    "        \"samples f1: {:.3f}\".format(mean_accuracy,\n",
    "                                    mean_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-interpretation",
   "metadata": {},
   "source": [
    "## 2.2. Metadata network\n",
    "**Results** : 4 epochs - 0.865 accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TabularNetBasic()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_meta = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    train_net(loader_train, net, optimizer, criterion, epoch)\n",
    "    mean_accuracy = test_net(loader_test,net)\n",
    "    test_acc_meta[epoch] = mean_accuracy\n",
    "\n",
    "    print(\"epoch: {:.3f}, accuracy: {:.3f} \".format(epoch, mean_accuracy))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-watts",
   "metadata": {},
   "source": [
    "## 2.3. Tabular & Residual network\n",
    "**Results** : 8 epochs -  0.995 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TabularCNNNetBasic()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_metaxres = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    train_net(loader_train, net, optimizer, criterion, epoch)\n",
    "    mean_accuracy = test_net(loader_test,net)\n",
    "    test_acc_metaxres[epoch] = mean_accuracy\n",
    "\n",
    "    print(\"epoch: {:.3f}, accuracy: {:.3f} \".format(epoch, mean_accuracy))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc, label = 'Residual')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_meta, label = 'Metadata')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_metaxres, label = 'Metadata & Residual')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-albert",
   "metadata": {
    "id": "fFggBB71DUYd"
   },
   "source": [
    "# 3. Building different model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-twenty",
   "metadata": {
    "id": "oKMUD771DhqL"
   },
   "source": [
    "## 3.1. AlexNet - Residual maps\n",
    "### 3.1.2 Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "concrete-conjunction",
   "metadata": {
    "executionInfo": {
     "elapsed": 5179,
     "status": "aborted",
     "timestamp": 1616692454727,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "D5s3kMmVv_1U"
   },
   "outputs": [],
   "source": [
    "net = AlexNetResidual()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "indirect-orchestra",
   "metadata": {
    "executionInfo": {
     "elapsed": 5174,
     "status": "aborted",
     "timestamp": 1616692454728,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "f0hNnGbswQOC"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4e4fd118a764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplens/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-redhead",
   "metadata": {},
   "source": [
    "### 3.1.2. Interpolation\n",
    "\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-forestry",
   "metadata": {
    "executionInfo": {
     "elapsed": 5168,
     "status": "aborted",
     "timestamp": 1616692454728,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "uz9vNVCD9tWA"
   },
   "outputs": [],
   "source": [
    "net = AlexNetResidual()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-algebra",
   "metadata": {
    "id": "r5xXe9fZUvcV"
   },
   "source": [
    "## 3.2. Resnet18 - Residual maps\n",
    "### 3.2.1. Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-monday",
   "metadata": {
    "executionInfo": {
     "elapsed": 5147,
     "status": "aborted",
     "timestamp": 1616692454731,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "1Hr1w_7s0Now"
   },
   "outputs": [],
   "source": [
    "net = resnet18maps(1,3)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-split",
   "metadata": {
    "executionInfo": {
     "elapsed": 5141,
     "status": "aborted",
     "timestamp": 1616692454731,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "6LMIVBqx0ROP"
   },
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-giving",
   "metadata": {},
   "source": [
    "### 3.2.2. Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-sudan",
   "metadata": {
    "executionInfo": {
     "elapsed": 5136,
     "status": "aborted",
     "timestamp": 1616692454732,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "6axEfVW00Kj_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = resnet18maps(1,3)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-barrier",
   "metadata": {
    "id": "0PpS3OPlWL1i"
   },
   "source": [
    "## 3.3. VGG16 - Residual maps\n",
    "### 3.3.1. Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-flooring",
   "metadata": {
    "executionInfo": {
     "elapsed": 5114,
     "status": "aborted",
     "timestamp": 1616692454734,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "jWiuE5X51TkG"
   },
   "outputs": [],
   "source": [
    "net = VGG16Residual()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-cause",
   "metadata": {
    "executionInfo": {
     "elapsed": 5107,
     "status": "aborted",
     "timestamp": 1616692454734,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "gBZBvZ6a1Wvv"
   },
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-jackson",
   "metadata": {},
   "source": [
    "### 3.3.2 Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG16Residual()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-belly",
   "metadata": {
    "id": "66C5ftu6cfFP"
   },
   "source": [
    "## 3.4. Dense Net 161 - Residual maps\n",
    "### 3.4.1 Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-aspect",
   "metadata": {
    "executionInfo": {
     "elapsed": 5079,
     "status": "aborted",
     "timestamp": 1616692454737,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "jTX_xhrfZ0wW"
   },
   "outputs": [],
   "source": [
    "net = densenet161()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-yahoo",
   "metadata": {
    "executionInfo": {
     "elapsed": 5074,
     "status": "aborted",
     "timestamp": 1616692454738,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "gV19-p4jau9u"
   },
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] = accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-hardwood",
   "metadata": {},
   "source": [
    "### 3.4.2 Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = densenet161()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-guidance",
   "metadata": {
    "executionInfo": {
     "elapsed": 5068,
     "status": "aborted",
     "timestamp": 1616692454738,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "qOcti75Qlfd1"
   },
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-attention",
   "metadata": {
    "id": "RFEJTNK8cug8"
   },
   "source": [
    "## 3.5. Google Net - Residual maps\n",
    "### 3.5.1 Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GoogLeNet(googlenet(True, True, None,224, dropout_rate=0.2, num_classes=3))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-citizenship",
   "metadata": {
    "executionInfo": {
     "elapsed": 5058,
     "status": "aborted",
     "timestamp": 1616692454740,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "dLURFuUAfG3a"
   },
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-picture",
   "metadata": {},
   "source": [
    "### 3.5.2 Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GoogLeNet(googlenet(True, True, None,224, dropout_rate=0.2, num_classes=3))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-attempt",
   "metadata": {
    "id": "FL0p7kKwc0CU"
   },
   "source": [
    "## 3.6. Squeeze Net 1_1  - Residual maps\n",
    "### 3.6.1 Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "physical-eligibility",
   "metadata": {
    "executionInfo": {
     "elapsed": 5047,
     "status": "aborted",
     "timestamp": 1616692454741,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "o3gMHYPdfH7C"
   },
   "outputs": [],
   "source": [
    "net = squeezenet1_1()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-celtic",
   "metadata": {},
   "source": [
    "### 3.6.2 Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = squeezenet1_1()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
