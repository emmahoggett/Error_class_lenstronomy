{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "editorial-devices",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from helpers.data_generation.file_management import read_hdf5\n",
    "from helpers.data_generation.error_generation_ki2 import Residual, CombineDataset\n",
    "from helpers.model.helpers_model import NeuralNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "necessary-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.75\n",
    "percent = np.array([0.005, 0.015, 0.005])\n",
    "size = 600\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "res = Residual()\n",
    "res.build(size, ratio = ratio, per_error = percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.75\n",
    "percent = np.array([0.005, 0.015, 0.005])\n",
    "size = 600\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "str_ID =  \"S\"+str(size)+\"R\"+str(int(ratio*100))\n",
    "[final_array, metadata] = read_hdf5(str_ID)\n",
    "metadata ['ID'] = np.arange(0,final_array.shape[0])\n",
    "data_set = CombineDataset(metadata,'ID','class',final_array)\n",
    "\n",
    "data_train, data_test = train_test_split(data_set,train_size=0.85,random_state=42)\n",
    "loader_test = DataLoader(data_test, batch_size = batch_size, num_workers = 0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exempt-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_name = ['AlexNet', 'ResNet18', 'SqueezeNet']\n",
    "\n",
    "k = 0\n",
    "\n",
    "final_pred = np.array([])\n",
    "for model_i in net_name:\n",
    "    net = NeuralNet(model_i, 'SGD/momentum')\n",
    "    net.load_checkpoint()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = []; targets = []\n",
    "        for data in loader_test:\n",
    "            images, _, labels = data\n",
    "            m = nn.\n",
    "            outputs = net.net(images)\n",
    "\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    if k == 0:\n",
    "        final_pred = np.round(np.asarray(predictions))\n",
    "        final_targets = np.asarray(targets)\n",
    "        k = 1\n",
    "    else: \n",
    "        final_pred = np.append(final_pred, np.round(np.asarray(predictions)), axis = 1)\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(final_pred, final_targets, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-courage",
   "metadata": {},
   "source": [
    "## Ensemble Machine learning\n",
    "\n",
    "### 1. Binary relevance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "usual-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hamming': 0.3,\n",
       " 'precision': 0.72,\n",
       " 'recall': 0.92,\n",
       " 'f1': 0.6933333333333332,\n",
       " 'exactmatch': 0.48,\n",
       " 'accuracy': 0.7,\n",
       " 'auc': 0.7222985347985349}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initialize Binary Relevance multi-label classifier\n",
    "# with an SVM classifier\n",
    "# SVM in scikit only supports the X matrix in sparse representation\n",
    "\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = SVC(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "net.calculate_metrics(predictions.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-cleaners",
   "metadata": {},
   "source": [
    "### 2. Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = ClassifierChain(GaussianNB())\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "net.calculate_metrics(predictions.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-invention",
   "metadata": {},
   "source": [
    "### 3. Multi Label Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expressed-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 1, 's': 0.5} nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hamming': 0.3,\n",
       " 'precision': 0.94,\n",
       " 'recall': 0.64,\n",
       " 'f1': 0.5866666666666667,\n",
       " 'exactmatch': 0.56,\n",
       " 'accuracy': 0.7,\n",
       " 'auc': 0.636523199023199}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'k': range(1,3), 's': [0.5, 0.7, 1.0]}\n",
    "score = 'roc_auc'\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, scoring=score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)\n",
    "classifier = MLkNN(k=1, s=0.5)\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "net.calculate_metrics(predictions.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-demographic",
   "metadata": {},
   "source": [
    "### 3. Label Power Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accredited-administrator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hamming': 0.38,\n",
       " 'precision': 0.68,\n",
       " 'recall': 0.92,\n",
       " 'f1': 0.6399999999999999,\n",
       " 'exactmatch': 0.48,\n",
       " 'accuracy': 0.62,\n",
       " 'auc': 0.651862026862027}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initialize LabelPowerset multi-label classifier with a RandomForest\n",
    "classifier = LabelPowerset(\n",
    "    classifier = RandomForestClassifier(n_estimators=100),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "net.calculate_metrics(predictions.toarray(),y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
