{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "german-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from helpers import read_hdf5, CombineDataset\n",
    "from lenshelpers import Residual\n",
    "\n",
    "from model.helpers_model import NeuralNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc, accuracy_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-november",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation Finished\n"
     ]
    }
   ],
   "source": [
    "# Build the four classes \n",
    "config_repo_model = 'data/configFile/config_model'\n",
    "ratio = 0.75\n",
    "percent = 0.01\n",
    "size = 3000\n",
    "\n",
    "res = Residual()\n",
    "res.build(size, ratio = ratio, per_error = percent)\n",
    "\n",
    "print('Data Generation Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appointed-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data Finished\n"
     ]
    }
   ],
   "source": [
    "str_ID = \"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "[final_array, metadata] = read_hdf5(str_ID, path = \"data/dataSet/\")\n",
    "metadata ['ID'] = np.arange(0,final_array.shape[0])\n",
    "\n",
    "data_set = CombineDataset(metadata,'ID','class',final_array)\n",
    "\n",
    "print('Reading Data Finished')\n",
    "data_train, data_test = train_test_split(data_set,train_size=0.9,random_state=42)\n",
    "\n",
    "batch_size = 50\n",
    "max_epoch = 70\n",
    "\n",
    "\n",
    "loader_train = DataLoader(data_train, batch_size = batch_size, shuffle = True, \n",
    "                          num_workers = 0, drop_last=True)\n",
    "\n",
    "loader_test = DataLoader(data_test, batch_size = batch_size, shuffle = True, \n",
    "                         num_workers = 0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1.000, auc: 0.540\n",
      "epoch: 2.000, auc: 0.554\n",
      "epoch: 3.000, auc: 0.574\n",
      "epoch: 4.000, auc: 0.594\n",
      "epoch: 5.000, auc: 0.616\n",
      "epoch: 6.000, auc: 0.653\n",
      "epoch: 7.000, auc: 0.693\n",
      "epoch: 8.000, auc: 0.695\n",
      "epoch: 9.000, auc: 0.707\n",
      "epoch: 10.000, auc: 0.712\n",
      "epoch: 12.000, auc: 0.723\n",
      "epoch: 14.000, auc: 0.749\n",
      "epoch: 15.000, auc: 0.762\n",
      "epoch: 16.000, auc: 0.763\n",
      "epoch: 17.000, auc: 0.782\n",
      "epoch: 18.000, auc: 0.788\n",
      "epoch: 19.000, auc: 0.803\n",
      "epoch: 20.000, auc: 0.818\n",
      "epoch: 21.000, auc: 0.821\n",
      "epoch: 22.000, auc: 0.829\n",
      "epoch: 24.000, auc: 0.835\n",
      "epoch: 25.000, auc: 0.840\n",
      "epoch: 30.000, auc: 0.849\n",
      "epoch: 36.000, auc: 0.859\n"
     ]
    }
   ],
   "source": [
    "metric = 'auc'\n",
    "netacc = NeuralNet('BasicCNN', 'Adam')\n",
    "for epoch in range(max_epoch):\n",
    "    netacc.train(loader_train)\n",
    "    res = netacc.test(loader_test, metric = metric)\n",
    "    \n",
    "print('Finished Training')\n",
    "epoch = netacc.load_checkpoint()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    for data in loader_test:\n",
    "        images, meta, labels = data\n",
    "        outputs = netacc.net(images)\n",
    "\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        result = netacc.calculate_metrics(np.round(np.array(predictions)), np.array(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate precision-recall curve\n",
    "precision0, recall0, thresholds0 = precision_recall_curve(np.array(targets)[:,0], np.array(predictions)[:,0])\n",
    "precision1, recall1, thresholds1 = precision_recall_curve(np.array(targets)[:,1], np.array(predictions)[:,1])\n",
    "\n",
    "plt.plot(recall0, precision0, label='Mass error')\n",
    "plt.plot(recall1, precision1, label='Source error')\n",
    "# axis labels\n",
    "plt.xlabel('Recall[-]')\n",
    "plt.ylabel('Precision[-]')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "\n",
    "plt.savefig('figures/metric/'+metric+'RecallPrecision.jpeg')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(np.array(targets)[:,0], np.array(predictions)[:,0])\n",
    "lr_fpr, lr_tpr, _ = roc_curve(np.array(targets)[:,1], np.array(predictions)[:,1])\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, label='Mass error')\n",
    "plt.plot(lr_fpr, lr_tpr, label='Source error')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate[-]')\n",
    "plt.ylabel('True Positive Rate[-]')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# show the plot\n",
    "plt.savefig('figures/metric/'+metric+'ROC.jpeg')\n",
    "plt.show()\n",
    "\n",
    "txt = \"AUC score: {:.3f}, with \"+metric+\" metric\" \n",
    "print(txt.format(result['auc']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
