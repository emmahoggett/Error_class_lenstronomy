{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sensitive-seeker",
   "metadata": {},
   "source": [
    "# Optimizers study \n",
    "\n",
    "In this file, we test optimizers performance over the baseline neural network model. \n",
    "\n",
    "Final results :\n",
    "\n",
    "    Optimizer: SGD with momentum\n",
    "    AUC score: 0.950\n",
    "    Normalization: Yes and No\n",
    "    \n",
    "\n",
    "\n",
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from statistics import mean\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from helpers.data_generation.file_management import read_hdf5\n",
    "from helpers.data_generation.error_generation_chi2 import Residual, CombineDataset\n",
    "from helpers.model.helpers_model import NeuralNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-prevention",
   "metadata": {},
   "source": [
    "## 1. Data generation\n",
    "\n",
    "We generate the data with the following features. We remove noise-like and obvious error maps from the data by adding $MSE$ image metric and a limitation on the amplitude of the dataset.\n",
    "\n",
    "* Parameters : \n",
    "    * Percentages of error : \n",
    "        [0.5\\% 1.5\\% 0.5\\%] \n",
    "    * Ratio : \n",
    "        75\\% \n",
    "    * Minimum mean square error : \n",
    "        $\\chi^2_{low} > 1.2$ \n",
    "    * Maximum absolute pixel amplitude : \n",
    "        $|g(n,m)| < 6$\n",
    "        \n",
    "        \n",
    "Where $g$ is an image and $g(n,m)$ is the pixel in line $n$ and column $m$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-florida",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratio = 0.75\n",
    "percent = np.array([0.005, 0.015, 0.005])\n",
    "size = 6000\n",
    "\n",
    "batch_size = 50\n",
    "max_epoch = 150\n",
    "\n",
    "opti_name = np.array(['SGD', 'Adam', 'SGD/momentum'])\n",
    "\n",
    "\n",
    "\n",
    "res = Residual()\n",
    "res.build(size, ratio = ratio, per_error = percent)\n",
    "\n",
    "str_ID =  \"S\"+str(size)+\"R\"+str(int(ratio*100))\n",
    "[final_array, metadata] = read_hdf5(str_ID)\n",
    "metadata ['ID'] = np.arange(0,final_array.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-board",
   "metadata": {},
   "source": [
    "## 2. Epoch and AUC optimizer selection \n",
    "\n",
    "This section focuses on the time of learning versus the model efficiency. \n",
    "* SGD :\n",
    "    * Normalized : \n",
    "        Epoch : 146 - AUC : 0.935\n",
    "    * Not normalized : \n",
    "        Epoch : 143 - AUC : 0.934\n",
    "* SGD/momentum ;\n",
    "    * Normalized : \n",
    "        Epoch : 57 - AUC : 0.945\n",
    "    * Not normalized : \n",
    "        Epoch : 124 - AUC : 0.946\n",
    "* Adam :\n",
    "    * Normalized : \n",
    "        Epoch : 22 - AUC : 0.950\n",
    "    * Not normalized : \n",
    "        Epoch : 91 - AUC : 0.939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for norm in np.array([True, False]):\n",
    "    data_set = CombineDataset(metadata,'ID','class',final_array,norm)\n",
    "\n",
    "    data_train, data_test = train_test_split(data_set,train_size=0.9,random_state=42)\n",
    "\n",
    "\n",
    "    loader_train = DataLoader(data_train, batch_size = batch_size, \n",
    "                            num_workers = 4, drop_last=True, pin_memory = True)\n",
    "\n",
    "    loader_test = DataLoader(data_test, batch_size = batch_size, \n",
    "                            num_workers = 4, drop_last=True, pin_memory = True)\n",
    "\n",
    "\n",
    "    for opti in opti_name:\n",
    "        print('----------------------------------------------------------------------------------')\n",
    "\n",
    "        test_SGDnorm = np.zeros(max_epoch)\n",
    "        netbasic = NeuralNet('BasicCNN', opti)\n",
    "        for epoch in range(max_epoch):\n",
    "            netbasic.train(loader_train)\n",
    "            res = netbasic.test(loader_test, verbose = False)\n",
    "            test_SGDnorm[epoch] = res\n",
    "        \n",
    "        if norm:\n",
    "            txt = \"Finished Training- Normalized: \"+ opti +\" - epoch: {:.3f} - auc: {:.3f} \\n\" \n",
    "            print(txt.format(np.argmax(netbasic.epoch_metric)+1, netbasic.max_met))\n",
    "            plt.plot(np.arange(1, max_epoch+1), test_SGDnorm, label='Norm '+opti)\n",
    "        else:\n",
    "            txt = \"Finished Training- Not normalized: \"+ opti +\" - epoch: {:.3f} - auc: {:.3f} \\n\" \n",
    "            print(txt.format(np.argmax(netbasic.epoch_metric)+1, netbasic.max_met))\n",
    "            plt.plot(np.arange(1, max_epoch+1), test_SGDnorm, label=opti)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('figures/baseline/optimizers.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-subscription",
   "metadata": {},
   "source": [
    "## 4. K-fold optimizer selection\n",
    "\n",
    "To select the optimizer of our problem, we perform a 5-fold approach to make sure of our final optimizer selection. \n",
    "\n",
    "* SGD/momentum ;\n",
    "    * normalized data AUC : 0.950\n",
    "    * not normalized data AUC : 0.950\n",
    "* Adam :\n",
    "    * normalized data AUC : 0.948\n",
    "    * not normalized data AUC : 0.949\n",
    "* SGD :\n",
    "    * normalized data AUC : 0.943\n",
    "    * not normalized data AUC : 0.938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata ['ID'] = np.arange(0,final_array.shape[0])\n",
    "\n",
    "data_set = CombineDataset(metadata,'ID','class',final_array)\n",
    "\n",
    "k_folds = 5 \n",
    "kfold = KFold(n_splits = k_folds, shuffle = True)\n",
    "\n",
    "\n",
    "for norm in np.array([False, True]):\n",
    "    data_set = CombineDataset(metadata,'ID','class',final_array, norm)\n",
    "    for opti in opti_name:\n",
    "        max_AUC = []\n",
    "        for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "            print(f'FOLD {fold}')\n",
    "            print('----------------------')\n",
    "\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "            loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler, num_workers = 4, pin_memory = True)\n",
    "            loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler, num_workers = 4, pin_memory = True)\n",
    "    \n",
    "\n",
    "            netbasic = NeuralNet('BasicCNN', opti)\n",
    "            while netbasic.current_epoch < max_epoch:\n",
    "                netbasic.train(loader_train)\n",
    "                res = netbasic.test(loader_test, verbose = False)\n",
    "            max_AUC.append(netbasic.max_met)\n",
    "            \n",
    "        print('----------------------------------------------------------------------------------')\n",
    "        if norm:\n",
    "            txt = \"Finished Training- Normalized: \"+ opti +\" - auc: {:.3f} \\n\" \n",
    "            print(txt.format(mean(max_AUC)))\n",
    "        else:\n",
    "            txt = \"Finished Training- Not normalized: \"+ opti +\" - auc: {:.3f} \\n\" \n",
    "            print(txt.format(mean(max_AUC)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
