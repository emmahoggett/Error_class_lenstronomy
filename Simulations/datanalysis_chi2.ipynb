{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis of the generated images and residuals without outliers\n",
    "\n",
    "In this notebook, the data-set is generated with lenstronomy. The aim is to show the data that will be used for the neural network and confirm if the generated data fits our expectations with simulated images.\n",
    "As we deal with and absolute error on the residuals, some percentage of error are tested to make sure that the error is difficult to see with the naked eye. \n",
    "Finally the distribution of variable and labels are checked in order to make sure that our dataset building is correct.\n",
    "\n",
    "Final configuration for the simulated images:\n",
    "Lens' mass variation :\n",
    "- Model : Power-law Elliptical Mass Distribution\n",
    "\n",
    ">$\\kappa = \\frac{3-\\gamma }{2}\\left ( \\frac{\\theta_E}{\\sqrt{q e_1^2+ e_2^2/q}} \\right )^{\\gamma-1}$\n",
    " \n",
    "* Einstein radius: $\\theta_E \\in \\mathcal{N}_{log}(\\mu:0,\\sigma:0.1)$\n",
    "\n",
    "* Power law slope: $\\gamma \\in \\mathcal{N}_{log}(\\mu:0.7,\\sigma:0.1)$\n",
    "* Ellipsity* : $e_1 \\in \\mathcal{N}(\\mu :0, \\sigma : 0.2)$   and $e_2 \\in \\mathcal{N}(\\mu :0, \\sigma : 0.2)$\n",
    "* Center : $x = 0$ and $y = 0$\n",
    "\n",
    "Source variation :\n",
    "* Model : Sersic ellipse\n",
    "* Amplitude : $amp \\in  \\mathcal{U}(20, 24)$\n",
    "* Sersic radius : $R_{sersic} \\in  \\mathcal{N}_{log}(\\mu:-0.7,\\sigma:0.4)$\n",
    "* Sersic index : $n_{sersic} \\in  \\mathcal{N}_{log}(\\mu:0.7,\\sigma:0.4)$\n",
    "* Ellipsity* : $e_1 \\in \\mathcal{U}(\\mu :0, \\sigma : 0.2)$   and $e_2 \\in \\mathcal{U}(\\mu :0, \\sigma : 0.2)$\n",
    "* Center : $x \\in \\mathcal{U}(-0.5,0.5)$ and $y \\in \\mathcal{U}(-0.5,0.5)$\n",
    "\n",
    "Note* : The ellipsity range is determined and is approximated with the following equations, where $q \\in \\mathcal{U}(0.7, 1)$ and $\\phi \\in \\mathcal{U}(0, \\frac{\\pi}{2})$\n",
    "\n",
    ">$e_1 = \\frac{1-q}{1+q}\\cos{(2\\phi)}$     and     $e_2 = \\frac{1-q}{1+q}\\sin{(2\\phi)} $\n",
    "    \n",
    "The added error is proportionnally defined such that each quantities is defined as following :\n",
    "\n",
    ">$A_err = A \\pm p A$\n",
    "\n",
    "Where $A$ is the current quantity value and $p$ the user defined percentage of error. \n",
    "\n",
    "The final data configuration parameters :\n",
    "* Size of the whole dataset: $s = 6000$\n",
    "* Ratio of error maps: $r = 75\\%$\n",
    "* Percentage of error : $p = \\begin{bmatrix}5\\% & 1.5\\% & 5\\%\\end{bmatrix}$\n",
    "\n",
    "In this data set outliers are not considered, which are noise-like error residual maps and maps with a maximal absolute amplitude superior to $6$. The bound to remove the noise-like data is by computing the Peak Signal to-Noise Ratio (PSNR) between a map that do not contain any noise and any errors and comparing it to the mean PSNR of maps that only contain noise. If the values is lower, the image is automatically discard, otherwise, the value is kept.\n",
    "\n",
    "Mean square error :\n",
    ">$MSE = \\frac{1}{NM}\\sum_{n= 0}^N \\sum_{m=0}^M $\n",
    "\n",
    "Peak Signal to-Noise Ratio : \n",
    ">$PSNR = $\n",
    "\n",
    "\n",
    "\n",
    "### 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from scipy.stats import chi2, chi, gaussian_kde\n",
    "\n",
    "from helpers.data_generation.file_management import*\n",
    "from helpers.data_generation.error_generation_chi2 import*\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build the data set\n",
    "\n",
    "The residual maps are generated and stored in the repository `data/dataset/` under the name `S[size]R[ratio]_lens.h5`, while the metadata is saved under the name `S[size]R[ratio]_meta.h5`. The `[size]` correspond to the number of images and the `[ratio]` is the percentage of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the four classes \n",
    "config_repo_model = 'data/configFile/config_model'\n",
    "size = 600; ratio = 0.75;\n",
    "percent = np.array([0.005, 0.015, 0.005])\n",
    "res = Residual()\n",
    "res.build(size, ratio = ratio, per_error = percent)\n",
    "\n",
    "print('Data Generation Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_ID =  \"S\"+str(size)+\"R\"+str(int(ratio*100))\n",
    "[final_array, metadata] = read_hdf5(str_ID)\n",
    "\n",
    "print('Reading data Finished')\n",
    "\n",
    "index = metadata.index\n",
    "\n",
    "indices_noerror = index[[col == [0,0] for col in metadata['class']]]\n",
    "indices_mass = index[[col == [1,0] for col in metadata['class']]]\n",
    "indices_source = index[[col == [0,1] for col in metadata['class']]]\n",
    "indices_masssource = index[[col == [1,1] for col in metadata['class']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot the residual maps and simulated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(9, 9, figsize=(36, 30), sharex=False, sharey=False)\n",
    "\n",
    "for count, k in enumerate(np.array([0, 3, 6])):\n",
    "    for i in range(0,9):\n",
    "        pos1 = axes[k,i].imshow(final_array[indices_mass[i+9*count],0,:,:], vmin=-6, vmax=6, origin='lower',cmap=plt.cm.BuPu_r)\n",
    "        pos2 = axes[k+1,i].imshow(final_array[indices_source[i+9*count],0,:,:], vmin=-6, vmax=6, origin='lower',cmap=plt.cm.BuPu_r)\n",
    "        pos3 = axes[k+2,i].imshow(final_array[indices_masssource[i+9*count],0,:,:], vmin=-6, vmax=6, origin='lower',cmap=plt.cm.BuPu_r)\n",
    "\n",
    "        axes[k,i].set_yticklabels([]); axes[k,i].set_xticklabels([])\n",
    "        axes[k+1,i].set_yticklabels([]); axes[k+1,i].set_xticklabels([])\n",
    "        axes[k+2,i].set_yticklabels([]); axes[k+2,i].set_xticklabels([])\n",
    "        f.colorbar(pos1, ax=axes[k,i]); f.colorbar(pos2, ax=axes[k+1,i])\n",
    "        f.colorbar(pos3, ax=axes[k+2,i])\n",
    "    \n",
    "    \n",
    "    pad = 5\n",
    "    font = 30\n",
    "\n",
    "    axes[k,0].annotate('Mass error', xy=(0, 0.5), xytext=(-axes[k,0].yaxis.labelpad - pad, 0),\n",
    "                       xycoords=axes[k,0].yaxis.label, textcoords='offset points', ha='right', va='center',fontsize=font)\n",
    "    axes[k+1,0].annotate('Source error', xy=(0, 0.5), xytext=(-axes[k+1,0].yaxis.labelpad - pad, 0),\n",
    "                       xycoords=axes[k+1,0].yaxis.label, textcoords='offset points', ha='right', va='center',fontsize=font)\n",
    "    axes[k+2,0].annotate('Mass &\\nsource error', xy=(0, 0.5), xytext=(-axes[k+2,0].yaxis.labelpad - pad, 0),\n",
    "                       xycoords=axes[k+2,0].yaxis.label, textcoords='offset points', ha='right', va='center',fontsize=font)\n",
    "    \n",
    "f.suptitle('Lenstronomy residual map with {:.1f}% of mass error and {:.1f}% of source error'.format(percent[0]*100, percent[1]*100), size = 'large',fontsize=font)\n",
    "plt.tight_layout(rect=[0, 0.02, 1, 0.97])\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "f.savefig('figures/datanalysis/'+str(int(percent[0]*100))+'percenterror_chi2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "cor = signal.correlate2d (final_array[indices_mass[0],:,:], final_array[indices_mass[0],:,:])\n",
    "\n",
    "f, axes = plt.subplots(8, 8, figsize=(48, 30), sharex=False, sharey=False)\n",
    "ran = 6\n",
    "for count, k in enumerate(np.array([0, 4,])):\n",
    "    for i in range(0,8):\n",
    "        cor_mass = signal.correlate2d (final_array[indices_mass[i+9*count],0,:,:], final_array[indices_mass[i+9*count],0,:,:])\n",
    "        cor_source = signal.correlate2d (final_array[indices_source[i+9*count],0,:,:], final_array[indices_source[i+9*count],0,:,:])\n",
    "        cor_sourcemass = signal.correlate2d (final_array[indices_masssource[i+9*count],0,:,:], final_array[indices_masssource[i+9*count],0,:,:])\n",
    "        cor_noerror = signal.correlate2d (final_array[indices_noerror[i+9*count],0,:,:], final_array[indices_noerror[i+9*count],0,:,:])\n",
    "        cor_mass = (cor_mass- np.mean(cor_mass))/np.std(cor_mass)\n",
    "        cor_source = (cor_source- np.mean(cor_source))/np.std(cor_source)\n",
    "        cor_sourcemass = (cor_sourcemass- np.mean(cor_sourcemass))/np.std(cor_sourcemass)\n",
    "        cor_noerror = (cor_noerror- np.mean(cor_noerror))/np.std(cor_noerror)\n",
    "        pos1 = axes[k,i].imshow(cor_mass,  vmin=-ran, vmax=ran, origin='lower',cmap=plt.cm.BuPu_r)\n",
    "        pos2 = axes[k+1,i].imshow(cor_source,  vmin=-ran, vmax=ran, origin='lower',cmap=plt.cm.BuPu_r)\n",
    "        pos3 = axes[k+2,i].imshow(cor_sourcemass, vmin=-ran, vmax=ran, origin='lower',cmap=plt.cm.BuPu_r)\n",
    "        pos4 = axes[k+3,i].imshow(cor_noerror, vmin=-ran, vmax=ran, origin='lower',cmap=plt.cm.BuPu_r)\n",
    "\n",
    "        axes[k,i].set_yticklabels([]); axes[k,i].set_xticklabels([])\n",
    "        axes[k+1,i].set_yticklabels([]); axes[k+1,i].set_xticklabels([])\n",
    "        axes[k+2,i].set_yticklabels([]); axes[k+2,i].set_xticklabels([])\n",
    "        axes[k+3,i].set_yticklabels([]); axes[k+3,i].set_xticklabels([])\n",
    "        f.colorbar(pos1, ax=axes[k,i]); f.colorbar(pos2, ax=axes[k+1,i]); f.colorbar(pos3, ax=axes[k+2,i]); f.colorbar(pos4, ax=axes[k+3,i])\n",
    "    \n",
    "    \n",
    "    pad = 5\n",
    "    font = 30\n",
    "\n",
    "    axes[k,0].annotate('Mass error', xy=(0, 0.5), xytext=(-axes[k,0].yaxis.labelpad - pad, 0),\n",
    "                       xycoords=axes[k,0].yaxis.label, textcoords='offset points', ha='right', va='center',fontsize=font)\n",
    "    axes[k+1,0].annotate('Source error', xy=(0, 0.5), xytext=(-axes[k+1,0].yaxis.labelpad - pad, 0),\n",
    "                       xycoords=axes[k+1,0].yaxis.label, textcoords='offset points', ha='right', va='center',fontsize=font)\n",
    "    axes[k+2,0].annotate('Mass &\\nsource error', xy=(0, 0.5), xytext=(-axes[k+2,0].yaxis.labelpad - pad, 0),\n",
    "                       xycoords=axes[k+2,0].yaxis.label, textcoords='offset points', ha='right', va='center',fontsize=font)\n",
    "    \n",
    "    axes[k+3,0].annotate('No error', xy=(0, 0.5), xytext=(-axes[k+3,0].yaxis.labelpad - pad, 0),\n",
    "                       xycoords=axes[k+3,0].yaxis.label, textcoords='offset points', ha='right', va='center',fontsize=font)\n",
    "f.suptitle('Lenstronomy residual map correlation', size = 'large')\n",
    "plt.tight_layout(rect=[0, 0.02, 1, 0.97])\n",
    "plt.show()\n",
    "f.savefig('figures/datanalysis/Autocorrelation_chi2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(10, 3), sharex=False, sharey=False)\n",
    "index = metadata.index\n",
    "\n",
    "indices_noerror = index[[col == [0,0] for col in metadata['class']]]\n",
    "\n",
    "for i in range(3):\n",
    "    pos = axes[i].imshow(final_array[indices_noerror[i],0,:,:], vmin=-6, vmax=6, origin='lower',cmap=plt.cm.BuPu_r)\n",
    "\n",
    "    axes[i].set_yticklabels([]); axes[i].set_xticklabels([])\n",
    "    f.colorbar(pos, ax=axes[i]);\n",
    "    \n",
    "pad = 5\n",
    "\n",
    "axes[0].annotate('No error', xy=(0, 0.5), xytext=(-axes[0].yaxis.labelpad - pad, 0),\n",
    "                   xycoords=axes[0].yaxis.label, textcoords='offset points', ha='right', va='center')\n",
    "\n",
    "f.suptitle('Lenstronomy residual map with no error', size = 'large')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "f.savefig('figures/datanalysis/Noerror_chi2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(9, 9, figsize=(36, 30), sharex=False, sharey=False)\n",
    "dataset_model = LensDataset(size = size, percent = percent)\n",
    "p_decal = 10\n",
    "\n",
    "for i in range(0,9):\n",
    "    for k in range(9):\n",
    "        \n",
    "        image_real = dataset_model.images[i+k*p_decal][0] + dataset_model.image_config.noise_for_model(model = dataset_model.images[i][0])\n",
    "        pos1 = axes[k,i].imshow(image_real, cmap = 'viridis', origin='lower')\n",
    "        axes[k,i].set_yticklabels([]); axes[k,i].set_xticklabels([])\n",
    "        f.colorbar(pos1, ax=axes[k,i])\n",
    "\n",
    "f.suptitle('Simulated images', size = 'large')\n",
    "f.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "f.savefig('figures/datanalysis/simulated_chi2.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot distributions\n",
    "\n",
    "### 3.1 Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dist = metadata.copy(deep=True)\n",
    "meta_dist.loc[[col == [0,0] for col in meta_dist['class']], 'class'] = 'NoErrors'\n",
    "meta_dist.loc[[col == [1,0] for col in meta_dist['class']], 'class'] = 'Mass'\n",
    "meta_dist.loc[[col == [0,1] for col in meta_dist['class']], 'class'] = 'Source'\n",
    "meta_dist.loc[[col == [1,1] for col in meta_dist['class']], 'class'] = 'Mass&Source'\n",
    "\n",
    "ax = sns.countplot(meta_dist['class'],label=\"Count\")\n",
    "fig = ax.get_figure()\n",
    "\n",
    "fig.savefig('figures/datanalysis/balancelabel_chi2.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Parameters distribution according to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_err = res.metadata_error.copy(deep=True)\n",
    "\n",
    "meta_err.loc[[col == [0,0] for col in meta_err['class']], 'class'] = 'NoMass'\n",
    "meta_err.loc[[col == [1,0] for col in meta_err['class']], 'class'] = 'Mass'\n",
    "meta_err.loc[[col == [0,1] for col in meta_err['class']], 'class'] = 'NoMass'\n",
    "meta_err.loc[[col == [1,1] for col in meta_err['class']], 'class'] = 'Mass'\n",
    "\n",
    "cols = meta_err.columns[2:6].tolist()\n",
    "cols.append('class')\n",
    "g = sns.pairplot(meta_err[cols], diag_kind=\"kde\", corner = True, hue=\"class\", palette = \"magma\")\n",
    "g.map_lower(sns.scatterplot, s=5)\n",
    "g.map_lower(sns.histplot, bins=300, pthresh=.1)\n",
    "g.map_lower(sns.kdeplot, levels=5, color=\"w\", linewidths=1)\n",
    "g.savefig('figures/datanalysis/statMass_chi2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_err = res.metadata_error.copy(deep=True)\n",
    "\n",
    "meta_err.loc[[col == [0,0] for col in meta_err['class']], 'class'] = 'NoSource'\n",
    "meta_err.loc[[col == [1,0] for col in meta_err['class']], 'class'] = 'NoSource'\n",
    "meta_err.loc[[col == [0,1] for col in meta_err['class']], 'class'] = 'Source'\n",
    "meta_err.loc[[col == [1,1] for col in meta_err['class']], 'class'] = 'Source'\n",
    "meta_err=meta_err.drop(columns=['percent'])\n",
    "\n",
    "\n",
    "cols = meta_err.columns[7:].tolist()\n",
    "g = sns.pairplot(meta_err[cols], diag_kind=\"kde\", corner = True, hue=\"class\", palette = \"magma\")\n",
    "g.map_lower(sns.scatterplot, s=5)\n",
    "g.map_lower(sns.histplot, bins=300, pthresh=.1)\n",
    "g.map_lower(sns.kdeplot, levels=5, color=\"w\", linewidths=1)\n",
    "g.savefig('figures/datanalysis/statSource_chi2.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Distribution of the distance between a image with an error & an image without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.axes_style(\"whitegrid\")\n",
    "dist_mass = [np.sum((final_array[indices_mass[i],0,:,:]-final_array[indices_noerror[i],0,:,:])**2)/64**2 for i in range(len(indices_noerror))]\n",
    "dist_source = [np.sum((final_array[indices_source[i],0,:,:]-final_array[indices_noerror[i],0,:,:])**2)/64**2 for i in range(len(indices_noerror))]\n",
    "dist_masssource = [np.sum((final_array[indices_masssource[i],0,:,:]-final_array[indices_noerror[i],0,:,:])**2)/64**2 for i in range(len(indices_noerror))]\n",
    "\n",
    "g = sns.kdeplot(dist_mass, label = 'Mass error', bw_adjust=.1)\n",
    "sns.kdeplot(dist_source, label = 'Source error', bw_adjust=.1)\n",
    "sns.kdeplot(dist_masssource, label = 'Mass & source error', bw_adjust=.1)\n",
    "plt.xlim([1.5, 5])\n",
    "plt.legend()\n",
    "plt.savefig('figures/datanalysis/distancefinal_chi2.jpeg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Mean distance of the mass : '+ str(mean(dist_mass))+ '\\nMean distance of the source : ' + str(mean(dist_source))+ \n",
    "      '\\nMean distance of the mass & the source : ' +  str(mean(dist_masssource)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Distribution of the Chi2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2, chi\n",
    "\n",
    "ki2_noerror = [np.sum(final_array[i,0,:,:]**2)/(final_array.shape[3]*final_array.shape[2])for i in indices_noerror]\n",
    "ki2_mass = [np.sum(final_array[i,0,:,:]**2)/(final_array.shape[3]*final_array.shape[2])for i in indices_mass]\n",
    "ki2_source = [np.sum(final_array[i,0,:,:]**2)/(final_array.shape[3]*final_array.shape[2])for i in indices_source]\n",
    "ki2_masssource = [np.sum(final_array[i,0,:,:]**2)/(final_array.shape[3]*final_array.shape[2])for i in indices_masssource]\n",
    "\n",
    "print('Chi2 mean of the mass : '+ str(mean(ki2_mass))+ '\\nChi2 mean of the source : ' + str(mean(ki2_source))+ \n",
    "      '\\nChi2 mean of the mass & the source : ' +  str(mean(ki2_masssource))+ '\\nChi2 mean of no error : ' + str(mean(ki2_noerror)))\n",
    "\n",
    "sns.kdeplot(ki2_mass, label = 'Mass error', bw_adjust=.1)\n",
    "sns.kdeplot(ki2_source, label = 'Source error', bw_adjust=.1)\n",
    "sns.kdeplot(ki2_masssource, label = 'Mass & source error', bw_adjust=.1)\n",
    "plt.xlim([0.5, 4])\n",
    "plt.legend()\n",
    "plt.savefig('figures/datanalysis/Chi2final_chi2.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_noise = np.asarray(res.rms_noise)\n",
    "noise_final = np.asarray([final_array[i,0,:,:] - 3*rms_noise[i,:,:] for i in range(size)])\n",
    "noise_final = noise_final.clip(min=0)\n",
    "\n",
    "ki2_noerror = [np.sum(noise_final[i,0,:,:]**2)/(final_array.shape[3]*final_array.shape[2])for i in indices_noerror]\n",
    "ki2_mass = [np.sum(noise_final[i,0,:,:]**2)/(final_array.shape[3]*final_array.shape[2])for i in indices_mass]\n",
    "ki2_source = [np.sum(noise_final[i,0,:,:]**2)/(final_array.shape[3]*final_array.shape[2])for i in indices_source]\n",
    "ki2_masssource = [np.sum(noise_final[i,0,:,:]**2)/(final_array.shape[3]*final_array.shape[2])for i in indices_masssource]\n",
    "\n",
    "print('Chi2 mean of the mass : '+ str(mean(ki2_mass))+ '\\nChi2 mean of the source : ' + str(mean(ki2_source))+ \n",
    "      '\\nChi2 mean of the mass & the source : ' +  str(mean(ki2_masssource))+ '\\nChi2 mean of no error : ' + str(mean(ki2_noerror)))\n",
    "\n",
    "\n",
    "sns.kdeplot(ki2_mass, label = 'Mass error', bw_adjust=.1)\n",
    "sns.kdeplot(ki2_source, label = 'Source error', bw_adjust=.1)\n",
    "sns.kdeplot(ki2_masssource, label = 'Mass & source error', bw_adjust=.1)\n",
    "plt.xlim([0, 2])\n",
    "plt.legend()\n",
    "plt.savefig('figures/datanalysis/Chi2Noisefinal_chi2.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, figsize=(10, 10), sharex='all', sharey='all',\n",
    "                       gridspec_kw=dict(left=0.1, right=0.9,bottom=0.1, top=0.9))\n",
    "percent = np.array([[0.005, 0.0142, 0.005], [0.005, 0.0142, 0.0049], [0.0074, 0.015, 0.0025]])\n",
    "size = 6000; ratio = 0.75;\n",
    "\n",
    "for ii in range(3):\n",
    "\n",
    "    res = Residual()\n",
    "    res.build(size, ratio = ratio, per_error = percent[ii,:])\n",
    "\n",
    "    str_ID =  \"S\"+str(size)+\"R\"+str(int(ratio*100))\n",
    "    [final_array, metadata] = read_hdf5(str_ID)\n",
    "\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "    index = metadata.index\n",
    "\n",
    "    indices_noerror = index[[col == [0,0] for col in metadata['class']]]\n",
    "    indices_mass = index[[col == [1,0] for col in metadata['class']]]\n",
    "    indices_source = index[[col == [0,1] for col in metadata['class']]]\n",
    "    indices_masssource = index[[col == [1,1] for col in metadata['class']]]\n",
    "\n",
    "    dist_mass = [np.sum((final_array[indices_mass[i],0,:,:]-final_array[indices_noerror[i],0,:,:])**2)/64**2 for i in range(len(indices_noerror))]\n",
    "    dist_source = [np.sum((final_array[indices_source[i],0,:,:]-final_array[indices_noerror[i],0,:,:])**2)/64**2 for i in range(len(indices_noerror))]\n",
    "    dist_masssource = [np.sum((final_array[indices_masssource[i],0,:,:]-final_array[indices_noerror[i],0,:,:])**2)/64**2 for i in range(len(indices_noerror))]\n",
    "    \n",
    "    dens_mass = gaussian_kde(dist_mass)\n",
    "    dens_source = gaussian_kde(dist_source)\n",
    "    dens_masssource = gaussian_kde(dist_masssource)\n",
    "    \n",
    "    y_mass = dens_mass(np.linspace(1.5,5,200))\n",
    "    y_source = dens_source(np.linspace(1.5,5,200))\n",
    "    y_masssource = dens_masssource(np.linspace(1.5,5,200))\n",
    "\n",
    "    print('Mean distance of the mass : '+ str(mean(dist_mass))+ '\\nMean distance of the source : ' + str(mean(dist_source))+ \n",
    "          '\\nMean distance of the mass & the source : ' +  str(mean(dist_masssource)))\n",
    "    \n",
    "    print('-------------------------')\n",
    "    print('Max density distance of the mass : '+ str(y_mass[np.argmax(y_mass)])+ '\\nMax density distance of the source : ' + str(y_source[np.argmax(y_source)])+ \n",
    "          '\\nMax density distance of the mass & the source : ' +  str(y_masssource[np.argmax(y_masssource)]))\n",
    "    \n",
    "    \n",
    "    sns.kdeplot(dist_mass, label = 'Mass error', bw_adjust=.1, ax=axes[ii])\n",
    "    sns.kdeplot(dist_source, label = 'Source error', bw_adjust=.1, ax=axes[ii])\n",
    "    sns.kdeplot(dist_masssource, label = 'Mass & source error', bw_adjust=.1, ax=axes[ii])\n",
    "    axes[ii].set_xlim([1.5, 5])\n",
    "    \n",
    "axes[0].title.set_text('Chi2')\n",
    "axes[1].title.set_text('Distance')\n",
    "axes[2].title.set_text('Chi2 with noise consideration')\n",
    "plt.legend()\n",
    "plt.savefig('figures/datanalysis/distance_chi2.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, figsize=(10, 10), sharex='all', sharey='all',\n",
    "                       gridspec_kw=dict(left=0.1, right=0.9,bottom=0.1, top=0.9))\n",
    "percent = np.array([[0.0074, 0.015, 0.0025], [0.005, 0.0142, 0.005], [0.005, 0.0142, 0.0049]])\n",
    "ratio = 0.75; size = 600\n",
    "\n",
    "for ii in range(3):\n",
    "\n",
    "    res = Residual()\n",
    "    res.build(size, ratio = ratio, per_error = percent[ii,:])\n",
    "\n",
    "    str_ID =  \"S\"+str(size)+\"R\"+str(int(ratio*100))\n",
    "    [final_array, metadata] = read_hdf5(str_ID)\n",
    "\n",
    "    print('Reading data Finished')\n",
    "\n",
    "    index = metadata.index\n",
    "\n",
    "    indices_noerror = index[[col == [0,0] for col in metadata['class']]]\n",
    "    indices_mass = index[[col == [1,0] for col in metadata['class']]]\n",
    "    indices_source = index[[col == [0,1] for col in metadata['class']]]\n",
    "    indices_masssource = index[[col == [1,1] for col in metadata['class']]]\n",
    "\n",
    "    ki2_noerror = [np.sum(final_array[i,:,:]**2)/(final_array.shape[2]*final_array.shape[3])for i in indices_noerror]\n",
    "    ki2_mass = [np.sum(final_array[i,:,:]**2)/(final_array.shape[2]*final_array.shape[3])for i in indices_mass]\n",
    "    ki2_source = [np.sum(final_array[i,:,:]**2)/(final_array.shape[2]*final_array.shape[3])for i in indices_source]\n",
    "    ki2_masssource = [np.sum(final_array[i,:,:]**2)/(final_array.shape[2]*final_array.shape[3])for i in indices_masssource]\n",
    "    \n",
    "    print('Chi2 mean of the mass : '+ str(mean(ki2_mass))+ '\\nChi2 mean of the source : ' + str(mean(ki2_source))+ \n",
    "      '\\nChi2 mean of the mass & the source : ' +  str(mean(ki2_masssource))+ '\\nChi2 mean of no error : ' + str(mean(ki2_noerror)))\n",
    "    \n",
    "    axes[ii].hist(ki2_noerror)\n",
    "    axes[ii].hist(ki2_mass)\n",
    "    axes[ii].hist(ki2_source)\n",
    "    axes[ii].hist(ki2_masssource)\n",
    "    axes[ii].set_xlim([0, 2])\n",
    "    \n",
    "axes[0].title.set_text('Chi2 with noise consideration')\n",
    "axes[1].title.set_text('Chi2')\n",
    "axes[2].title.set_text('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, figsize=(10, 10), sharex='all', sharey='all',\n",
    "                       gridspec_kw=dict(left=0.1, right=0.9,bottom=0.1, top=0.9))\n",
    "percent = np.array([[0.0074, 0.015, 0.0025], [0.005, 0.0142, 0.005], [0.005, 0.0142, 0.0049]])\n",
    "ratio = 0.75;\n",
    "\n",
    "percent[0,:] = 0.8*np.array([0.0074, 0.015, 0.0025])\n",
    "for ii in range(3):\n",
    "\n",
    "    res = Residual()\n",
    "    res.build(size, ratio = ratio, per_error = percent[ii,:])\n",
    "\n",
    "    str_ID =  \"S\"+str(size)+\"R\"+str(int(ratio*100))\n",
    "    [final_array, metadata] = read_hdf5(str_ID)\n",
    "\n",
    "    print('Reading data Finished')\n",
    "\n",
    "    index = metadata.index\n",
    "\n",
    "    indices_noerror = index[[col == [0,0] for col in metadata['class']]]\n",
    "    indices_mass = index[[col == [1,0] for col in metadata['class']]]\n",
    "    indices_source = index[[col == [0,1] for col in metadata['class']]]\n",
    "    indices_masssource = index[[col == [1,1] for col in metadata['class']]]\n",
    "\n",
    "    rms_noise = np.asarray(res.rms_noise)\n",
    "    noise_final = np.asarray([final_array[i,0,:,:] - 3*rms_noise[i,:,:] for i in range(size)])\n",
    "    noise_final = noise_final.clip(min=0)\n",
    "\n",
    "    ki2_noerror = [np.sum(noise_final[i,:,:]**2)/(final_array.shape[2]*final_array.shape[3])for i in indices_noerror]\n",
    "    ki2_mass = [np.sum(noise_final[i,:,:]**2)/(final_array.shape[2]*final_array.shape[3])for i in indices_mass]\n",
    "    ki2_source = [np.sum(noise_final[i,:,:]**2)/(final_array.shape[2]*final_array.shape[3])for i in indices_source]\n",
    "    ki2_masssource = [np.sum(noise_final[i,:,:]**2)/(final_array.shape[2]*final_array.shape[3])for i in indices_masssource]\n",
    "\n",
    "    print('Chi2 mean of the mass : '+ str(mean(ki2_mass))+ '\\nChi2 mean of the source : ' + str(mean(ki2_source))+ \n",
    "          '\\nChi2 mean of the mass & the source : ' +  str(mean(ki2_masssource))+ '\\nChi2 mean of no error : ' + str(mean(ki2_noerror)))\n",
    "    \n",
    "    sns.kdeplot(ki2_mass, label = 'Mass error', bw_adjust=.1, ax=axes[ii])\n",
    "    sns.kdeplot(ki2_source, label = 'Source error', bw_adjust=.1, ax=axes[ii])\n",
    "    sns.kdeplot(ki2_masssource, label = 'Mass & source error', bw_adjust=.1, ax=axes[ii])\n",
    "    axes[ii].set_xlim([0, 2])\n",
    "    \n",
    "axes[0].title.set_text('Chi2 with noise consideration')\n",
    "axes[1].title.set_text('Chi2')\n",
    "axes[2].title.set_text('Distance')\n",
    "plt.legend()\n",
    "plt.savefig('figures/datanalysis/Chi2Noise_chi2.jpeg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
