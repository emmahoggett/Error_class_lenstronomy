{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from helpers import*\n",
    "from lenshelpers import*\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capable-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data Finished\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.DataFrame()\n",
    "for i in np.arange(1,4):\n",
    "    str_ID = \"E\"+str(i)+\"P\"+str(percent)\"R\"+str(ratio)\n",
    "    [img, meta] = read_hdf5(str_ID, path = \"data/dataSet/\")\n",
    "    metadata = pd.concat([metadata,meta], ignore_index=True)\n",
    "    if i == 1:\n",
    "        final_array = img\n",
    "    else:\n",
    "         final_array = np.concatenate((final_array, img))\n",
    "metadata ['ID'] = np.arange(0,final_array.shape[0])\n",
    "data_set = CombineDataset(metadata,'ID','class',final_array)\n",
    "\n",
    "print('Reading Data Finished')\n",
    "data_train, data_test = train_test_split(data_set,train_size=0.9,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dangerous-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 50\n",
    "batch_size_test = 10\n",
    "max_epoch = 10\n",
    "\n",
    "loader_train = DataLoader(data_train, batch_size = batch_size_train, shuffle = True, \n",
    "                          num_workers = 0, drop_last=True)\n",
    "\n",
    "loader_test = DataLoader(data_test, batch_size = batch_size_test, shuffle = True, \n",
    "                         num_workers = 0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informational-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_conv_output(in_size, padding, stride, kernel):\n",
    "    layer_number = 0; k = 0\n",
    "    out_size = (in_size + 2* padding[k] -kernel[k])/stride[k] + 1\n",
    "    k = 1\n",
    "    while True:\n",
    "        layer_number += 1\n",
    "        in_size = out_size\n",
    "        out_size = (in_size + 2* padding[k] -kernel[k])/stride[k] + 1\n",
    "        if k == 1: k = 0\n",
    "        else: k = 1\n",
    "        if out_size < 5:\n",
    "            break\n",
    "        \n",
    "    return in_size, layer_number\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, out_linear, out_conv, stride, padding, kernel, activation, batch_norm = False, in_size:int = 64, in_channel:int = 1, num_classes:int = 3):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.out_size, self.conv_number =  compute_conv_output(in_size, padding, stride, kernel)\n",
    "        self.nb_linear = out_linear.shape[0]\n",
    "        self.out_linear = out_linear; self.out_linear[0] = out_conv[-1]*self.out_size*self.out_size\n",
    "        \n",
    "        self.out_linear[-1] = num_classes; self.batch_norm = batch_norm\n",
    "        self.out_conv = out_conv; self.out_conv[0] = in_channel\n",
    "        self.stride = stride; self.padding = padding\n",
    "        self.kernel = kernel; \n",
    "        \n",
    "        self.activation_layer = activation_func(activation)\n",
    "        self.maxpool_layer = nn.MaxPool2d(kernel_size=kernel[1], stride=stride[1], padding=padding[1])\n",
    "        \n",
    "        self.layers_conv = nn.ModuleList()\n",
    "        for i in np.arange(0, self.out_conv.shape[0]-1):\n",
    "            self.layers_conv.append(nn.Conv2d(self.out_conv[i], self.out_conv[i+1], kernel_size=self.kernel[0], stride=self.stride[0], padding=self.padding[0]))\n",
    "            #if batch_norm:\n",
    "                #self.layers_conv.append(nn.BatchNorm2d(self.out_conv[i+1]))\n",
    "        \n",
    "        self.layers_linear = nn.ModuleList()\n",
    "        for i in np.arange(0, self.out_linear.shape[0]-1):\n",
    "            self.layers_conv.append(nn.Linear(self.out_linear[i], self.out_linear[i+1]))\n",
    "            self.layers_conv.append(activation_func(self.activation))\n",
    "            \n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "    def activation_func(activation):\n",
    "        return  nn.ModuleDict([\n",
    "            ['relu', nn.ReLU(inplace=True)],\n",
    "            ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "            ['selu', nn.SELU(inplace=True)],\n",
    "            ['none', nn.Identity()]])[activation] \n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        for layer in self.layers_conv[:-1]:\n",
    "            x = self.activation_layer(layer(x))\n",
    "            x = self.maxpool_layer(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        for layer in self.layers_linear[:-1]:\n",
    "            self.classifier = linear_layer(self.out_linear[i], self.out_linear[i+1])\n",
    "            x = self.classifier(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classified-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "strides_ = np.power(2,np.arange(0,4))\n",
    "paddings_ = np.arange(0,4)\n",
    "kernels_ = np.arange(3,10)\n",
    "batch_norms_ = np.array([True, False])\n",
    "activations_ = np.array(['relu','leaky_relu','selu','none'])\n",
    "zero_paddings_ = np.array([0,5,10,20,30])\n",
    "nb_linear_layers_ = np.arange(2,10)\n",
    "\n",
    "range_Nunit_ = np.power(5,np.arange(1,6))\n",
    "\n",
    "\n",
    "curr_stride = np.array([strides_[0],strides_[0]])\n",
    "curr_padding = np.array([paddings_[0],paddings_[0]])\n",
    "curr_kernel = np.array([kernels_[0],kernels_[0]])\n",
    "curr_zero_padding = zero_paddings_[0]\n",
    "curr_nb_linear_layer = nb_linear_layers_[0]\n",
    "in_size = 64 + curr_zero_padding\n",
    "\n",
    "out_size, layer_number = compute_conv_output(in_size, curr_padding, curr_stride, curr_kernel)\n",
    "\n",
    "curr_conv = np.ones(layer_number)*range_Nunit_[3]\n",
    "curr_linear = np.ones(curr_nb_linear_layer)*range_Nunit_[3]\n",
    "\n",
    "curr_activation = activations_[0]\n",
    "curr_batch = batch_norms_[0]\n",
    "max_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affiliated-anxiety",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (numpy.float64, numpy.float64, numpy.int64, numpy.int64), but expected one of:\n * (*, torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-31d1ccad9c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomCNN\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurr_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_padding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7cd8f2c04b09>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, out_linear, out_conv, stride, padding, kernel, activation, batch_norm, in_size, in_channel, num_classes)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_conv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_conv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplens/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m    410\u001b[0m         super(Conv2d, self).__init__(\n\u001b[1;32m    411\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             False, _pair(0), groups, bias, padding_mode)\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplens/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             self.weight = Parameter(torch.Tensor(\n\u001b[0;32m---> 78\u001b[0;31m                 out_channels, in_channels // groups, *kernel_size))\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (numpy.float64, numpy.float64, numpy.int64, numpy.int64), but expected one of:\n * (*, torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "net = CustomCNN (curr_linear, curr_conv, curr_stride, curr_padding, curr_kernel, curr_activation, batch_norm = curr_batch, in_size = in_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, 28):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_metaxres = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    train_net(loader_train, net, optimizer, criterion, epoch)\n",
    "    mean_accuracy = test_net(loader_test,net)\n",
    "    test_acc_metaxres[epoch] = mean_accuracy\n",
    "\n",
    "    print(\"epoch: {:.3f}, accuracy: {:.3f} \".format(epoch, mean_accuracy))\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
