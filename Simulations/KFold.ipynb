{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "renewable-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from helpers.data_generation.file_management import read_hdf5\n",
    "from helpers.data_generation.error_generation_chi2 import Residual, CombineDataset\n",
    "from helpers.model.helpers_model import NeuralNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collectible-theory",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b3994d5b0ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpercent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data building finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Error_class_lenstronomy/Simulations/helpers/data_generation/error_generation_chi2.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, size, ratio, per_error, num_label, center_x, center_y, mass_range, source_range, lower_mse, upp_bound, path_data)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0msize_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0miter_i\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mnew_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_image_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_mse_\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupp_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                     \u001b[0miter_i\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Error_class_lenstronomy/Simulations/helpers/data_generation/error_generation_chi2.py\u001b[0m in \u001b[0;36m_build_image_\u001b[0;34m(self, dataset_model, iter_i, errorID)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mdict_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mkwargs_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdict_err\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrorID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mimg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_ps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mimage_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/ImSim/image_model.py\u001b[0m in \u001b[0;36mimage\u001b[0;34m(self, kwargs_lens, kwargs_source, kwargs_lens_light, kwargs_ps, kwargs_extinction, kwargs_special, unconvolved, source_add, lens_light_add, point_source_add)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msource_add\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             model += self.source_surface_brightness(kwargs_source, kwargs_lens, kwargs_extinction=kwargs_extinction,\n\u001b[0;32m--> 260\u001b[0;31m                                                     kwargs_special=kwargs_special, unconvolved=unconvolved)\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlens_light_add\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlens_surface_brightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs_lens_light\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munconvolved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munconvolved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/ImSim/image_model.py\u001b[0m in \u001b[0;36msource_surface_brightness\u001b[0;34m(self, kwargs_source, kwargs_lens, kwargs_extinction, kwargs_special, unconvolved, de_lensed, k, update_pixelbased_mapping)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                                        \u001b[0mkwargs_extinction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_extinction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                                        \u001b[0mkwargs_special\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_special\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                                        unconvolved=unconvolved, de_lensed=de_lensed, k=k)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     def _source_surface_brightness_analytical(self, kwargs_source, kwargs_lens=None, kwargs_extinction=None, kwargs_special=None,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/ImSim/image_model.py\u001b[0m in \u001b[0;36m_source_surface_brightness_analytical\u001b[0;34m(self, kwargs_source, kwargs_lens, kwargs_extinction, kwargs_special, unconvolved, de_lensed, k)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0msource_light\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSourceModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface_brightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mra_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0msource_light\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_flux_joint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mra_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             source_light *= self._extinction.extinction(ra_grid, dec_grid, kwargs_extinction=kwargs_extinction,\n\u001b[1;32m    149\u001b[0m                                                         kwargs_special=kwargs_special)\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/ImSim/image2source_mapping.py\u001b[0m in \u001b[0;36mimage_flux_joint\u001b[0;34m(self, x, y, kwargs_lens, kwargs_source, k)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_source_plane\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mx_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lensModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mray_shooting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface_brightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/LensModel/lens_model.py\u001b[0m in \u001b[0;36mray_shooting\u001b[0;34m(self, x, y, kwargs, k)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msource\u001b[0m \u001b[0mplane\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mplane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlens_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mray_shooting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfermat_potential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/LensModel/single_plane.py\u001b[0m in \u001b[0;36mray_shooting\u001b[0;34m(self, x, y, kwargs, k)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msource\u001b[0m \u001b[0mplane\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mplane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/LensModel/single_plane.py\u001b[0m in \u001b[0;36malpha\u001b[0;34m(self, x, y, kwargs, k)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbool_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mf_x_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_y_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0mf_x\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf_x_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf_y\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf_y_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/LensModel/Profiles/pemd.py\u001b[0m in \u001b[0;36mderivatives\u001b[0;34m(self, x, y, theta_E, gamma, e1, e2, center_x, center_y)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeflection\u001b[0m \u001b[0mangles\u001b[0m \u001b[0malpha_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspemd_smooth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_s_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lenstronomy/LensModel/Profiles/spemd.py\u001b[0m in \u001b[0;36mderivatives\u001b[0;34m(self, x, y, theta_E, gamma, e1, e2, s_scale, center_x, center_y)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mcompute_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_fastell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fastell4py_bool\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_not_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompute_bool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mf_x_prim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_y_prim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastell4py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastelldefl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_fastell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mf_x_prim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_y_prim\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastell4py-0.1.0-py3.7-linux-x86_64.egg/fastell4py/fastell4py.py\u001b[0m in \u001b[0;36mfastelldefl\u001b[0;34m(x1, x2, q, gam, arat, s2)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mdefl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdefl2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0m_fastell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastelldefl_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefl1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0malpha2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefl2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ratio = 0.75\n",
    "percent = np.array([0.005, 0.015, 0.005])\n",
    "size = 6000\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "res = Residual()\n",
    "res.build(size, ratio = ratio, per_error = percent)\n",
    "print('Data building finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ID =  \"S\"+str(size)+\"R\"+str(int(ratio*100))\n",
    "[final_array, metadata] = read_hdf5(str_ID)\n",
    "metadata ['ID'] = np.arange(0,final_array.shape[0])\n",
    "\n",
    "data_set = CombineDataset(metadata,'ID','class',final_array)\n",
    "\n",
    "k_folds = 5 \n",
    "kfold = KFold(n_splits = k_folds, shuffle = True)\n",
    "batch_size = 50; max_epoch = 100\n",
    "\n",
    "print('Reading Data Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-couple",
   "metadata": {},
   "source": [
    "## 2. Convolutionnal neural network (CNN)\n",
    "### 2.0 Baseline\n",
    "\n",
    "Results:\n",
    "* Baseline - SGD : \n",
    "    * Mean AUCROC - Not normalized : 0.870\n",
    "    * Mean AUCROC - Normalized : \n",
    "* Baseline - Adam : \n",
    "    * Mean AUCROC - Not normalized: 0.903\n",
    "    * Mean AUCROC - Normalized : 0.\n",
    "* Baseline - SGD/momentum : \n",
    "    * Mean AUCROC - Not normalized : 0.906\n",
    "    * Mean AUCROC - Normalized : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('BasicCNN', 'SGD/momentum')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    data_set = CombineDataset(metadata,'ID','class',final_array, False)\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('BasicCNN', 'SGD/momentum')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('BasicCNN', 'Adam')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    data_set = CombineDataset(metadata,'ID','class',final_array, True)\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('BasicCNN', 'Adam')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('BasicCNN', 'SGD')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-theta",
   "metadata": {},
   "source": [
    "### 2.1. Spatial exploitation CNN\n",
    "\n",
    "Results :\n",
    "* AlexNet : Epoch : 17 - AUCROC : 0.974 - AUCROC Mass : 0.998 - AUCROC Source 0.949\n",
    "* VGG16 : Epoch : - AUCROC : \n",
    "* GoogleNet : Epoch : - AUCROC : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('AlexNet', 'SGD/momentum')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')\n",
    "\n",
    "print('Finished Training : AlexNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('VGG11', 'SGD/momentum')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')\n",
    "\n",
    "print('Finished Training : VGG11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('GoogleNet', 'SGD/momentum')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')\n",
    "\n",
    "print('Finished Training : GoogleNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-conflict",
   "metadata": {},
   "source": [
    "### 2.2. Multi-path exploitation CNN\n",
    "\n",
    "Results :\n",
    "* ResNet18 : Epoch : - AUCROC : \n",
    "* DenseNet161 : Epoch : - AUCROC : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('ResNet18', 'SGD/momentum')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')\n",
    "\n",
    "print('Finished Training : ResNet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('DenseNet161', 'SGD/momentum')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')\n",
    "\n",
    "print('Finished Training : DenseNet161')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-yacht",
   "metadata": {},
   "source": [
    "### 2.3. Ressource limited CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_AUC = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    loader_train = DataLoader(data_set, batch_size = batch_size, sampler = train_subsampler)\n",
    "    loader_test = DataLoader(data_set, batch_size = batch_size, sampler = test_subsampler)\n",
    "    \n",
    "    netbasic = NeuralNet('SqueezeNet', 'SGD/momentum')\n",
    "    while netbasic.current_epoch < max_epoch:\n",
    "        netbasic.train(loader_train)\n",
    "        res = netbasic.test(loader_test, verbose = False)\n",
    "    max_AUC.append(netbasic.max_met)\n",
    "\n",
    "print(f'AUC : {mean(max_AUC)}')\n",
    "\n",
    "print('Finished Training : SqueezeNet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
