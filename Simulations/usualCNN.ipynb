{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "subjective-doctrine",
   "metadata": {
    "id": "written-sample"
   },
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "devoted-linux",
   "metadata": {
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1616692453475,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "comfortable-tucson"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from helpers import*\n",
    "from lenshelpers import*\n",
    "\n",
    "from model.baseline import*\n",
    "from model.densenet import*\n",
    "from model.alexnet import*\n",
    "from model.resnet18 import*\n",
    "from model.vgg16 import*\n",
    "from model.googLeNet import*\n",
    "from model.squeezeNet import*\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-charleston",
   "metadata": {
    "id": "enhanced-enterprise"
   },
   "source": [
    "# 1. Building the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sticky-ending",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 5231,
     "status": "error",
     "timestamp": 1616692454742,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "intermediate-blood",
    "outputId": "c1d905f2-e341-4469-ac08-4f56582db157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation Finished\n"
     ]
    }
   ],
   "source": [
    "# Build the four classes \n",
    "config_repo_model = 'data/configFile/config_model'\n",
    "\n",
    "size = 500\n",
    "for i in np.arange(1,4):\n",
    "    #model_name = config_repo_model + str(i) + '.yaml'\n",
    "    res = Residual(size)\n",
    "    res.build(i)\n",
    "\n",
    "print('Data Generation Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "commercial-salem",
   "metadata": {
    "executionInfo": {
     "elapsed": 5206,
     "status": "aborted",
     "timestamp": 1616692454724,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "j4ngxjJlpBa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data Finished\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.DataFrame()\n",
    "for i in np.arange(1,4):\n",
    "    [img, meta] = read_hdf5(i, path = \"data/dataSet/\")\n",
    "    metadata = pd.concat([metadata,meta], ignore_index=True)\n",
    "    if i == 1:\n",
    "        final_array = img\n",
    "    else:\n",
    "         final_array = np.concatenate((final_array, img))\n",
    "metadata ['ID'] = np.arange(0,final_array.shape[0])\n",
    "data_set = CombineDataset(metadata,'ID','class',final_array)\n",
    "\n",
    "print('Reading Data Finished')\n",
    "data_train, data_test = train_test_split(data_set,train_size=0.9,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "champion-letters",
   "metadata": {
    "executionInfo": {
     "elapsed": 5201,
     "status": "aborted",
     "timestamp": 1616692454725,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "UkL0TbTeB092"
   },
   "outputs": [],
   "source": [
    "batch_size_train = 50\n",
    "batch_size_test = 10\n",
    "max_epoch = 10\n",
    "\n",
    "\n",
    "loader_train = DataLoader(data_train, batch_size = batch_size_train, shuffle = True, \n",
    "                          num_workers = 0, drop_last=True)\n",
    "\n",
    "loader_test = DataLoader(data_test, batch_size = batch_size_test, shuffle = True, \n",
    "                         num_workers = 0, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-cambridge",
   "metadata": {
    "id": "behind-benchmark"
   },
   "source": [
    "# 2. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-export",
   "metadata": {
    "id": "jRnYdliz-86r"
   },
   "source": [
    "## 2.1. Residual network\n",
    "\n",
    "**Results** : 6 epochs - 0.993 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hydraulic-simulation",
   "metadata": {
    "executionInfo": {
     "elapsed": 5195,
     "status": "aborted",
     "timestamp": 1616692454725,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "Epv5bSQ8_2v6"
   },
   "outputs": [],
   "source": [
    "net = CNNNetBasic()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interim-insight",
   "metadata": {
    "executionInfo": {
     "elapsed": 5190,
     "status": "aborted",
     "timestamp": 1616692454726,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "6jdGxSbwAkOV"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-05bead943a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmean_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader_train' is not defined"
     ]
    }
   ],
   "source": [
    "test_acc = np.zeros(max_epoch)\n",
    "# Optimal number of epochs : 6 epochs - 0.993 accuracy\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    train_net(loader_train, net, optimizer, criterion, epoch)\n",
    "    mean_accuracy = test_net(loader_test,net)\n",
    "    test_acc[epoch] = mean_accuracy\n",
    "\n",
    "    print(\"epoch: {:.3f}, accuracy: {:.3f} \".format(epoch, mean_accuracy))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-council",
   "metadata": {
    "executionInfo": {
     "elapsed": 5185,
     "status": "aborted",
     "timestamp": 1616692454727,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "9chu_f9-Ao6m"
   },
   "outputs": [],
   "source": [
    "f1_samples = 0\n",
    "accuracy = 0\n",
    "iteration = 0\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    for data in loader_test:\n",
    "        images, meta_img, labels = data\n",
    "        outputs = net(images)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "        f1_samples+=result['samples/f1']\n",
    "        accuracy+=result['samples/recall']\n",
    "        iteration+=1\n",
    "\n",
    "\n",
    "mean_f1 = f1_samples/(iteration+1)\n",
    "mean_accuracy =accuracy/(iteration+1)\n",
    "\n",
    "print(\"accuracy: {:.3f} \"\n",
    "        \"samples f1: {:.3f}\".format(mean_accuracy,\n",
    "                                    mean_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-digit",
   "metadata": {},
   "source": [
    "## 2.2. Metadata network\n",
    "**Results** : 4 epochs - 0.865 accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TabularNetBasic()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_meta = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    train_net(loader_train, net, optimizer, criterion, epoch)\n",
    "    mean_accuracy = test_net(loader_test,net)\n",
    "    test_acc_meta[epoch] = mean_accuracy\n",
    "\n",
    "    print(\"epoch: {:.3f}, accuracy: {:.3f} \".format(epoch, mean_accuracy))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-server",
   "metadata": {},
   "source": [
    "## 2.3. Tabular & Residual network\n",
    "**Results** : 8 epochs -  0.995 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TabularCNNNetBasic()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_metaxres = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    train_net(loader_train, net, optimizer, criterion, epoch)\n",
    "    mean_accuracy = test_net(loader_test,net)\n",
    "    test_acc_metaxres[epoch] = mean_accuracy\n",
    "\n",
    "    print(\"epoch: {:.3f}, accuracy: {:.3f} \".format(epoch, mean_accuracy))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc, label = 'Residual')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_meta, label = 'Metadata')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_metaxres, label = 'Metadata & Residual')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-stopping",
   "metadata": {
    "id": "fFggBB71DUYd"
   },
   "source": [
    "# 3. Building different model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-medicaid",
   "metadata": {
    "id": "oKMUD771DhqL"
   },
   "source": [
    "## 3.1. AlexNet - Residual maps\n",
    "### 3.1.2 Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "married-metropolitan",
   "metadata": {
    "executionInfo": {
     "elapsed": 5179,
     "status": "aborted",
     "timestamp": 1616692454727,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "D5s3kMmVv_1U"
   },
   "outputs": [],
   "source": [
    "net = AlexNetResidual()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "recognized-pioneer",
   "metadata": {
    "executionInfo": {
     "elapsed": 5174,
     "status": "aborted",
     "timestamp": 1616692454728,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "f0hNnGbswQOC"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4e4fd118a764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplens/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-ribbon",
   "metadata": {},
   "source": [
    "### 3.1.2. Interpolation\n",
    "\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-flood",
   "metadata": {
    "executionInfo": {
     "elapsed": 5168,
     "status": "aborted",
     "timestamp": 1616692454728,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "uz9vNVCD9tWA"
   },
   "outputs": [],
   "source": [
    "net = AlexNetResidual()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-purchase",
   "metadata": {
    "id": "r5xXe9fZUvcV"
   },
   "source": [
    "## 3.2. Resnet18 - Residual maps\n",
    "### 3.2.1. Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-algebra",
   "metadata": {
    "executionInfo": {
     "elapsed": 5147,
     "status": "aborted",
     "timestamp": 1616692454731,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "1Hr1w_7s0Now"
   },
   "outputs": [],
   "source": [
    "net = resnet18maps(1,3)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-replication",
   "metadata": {
    "executionInfo": {
     "elapsed": 5141,
     "status": "aborted",
     "timestamp": 1616692454731,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "6LMIVBqx0ROP"
   },
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-bunch",
   "metadata": {},
   "source": [
    "### 3.2.2. Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-timber",
   "metadata": {
    "executionInfo": {
     "elapsed": 5136,
     "status": "aborted",
     "timestamp": 1616692454732,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "6axEfVW00Kj_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = resnet18maps(1,3)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-wayne",
   "metadata": {
    "id": "0PpS3OPlWL1i"
   },
   "source": [
    "## 3.3. VGG16 - Residual maps\n",
    "### 3.3.1. Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-league",
   "metadata": {
    "executionInfo": {
     "elapsed": 5114,
     "status": "aborted",
     "timestamp": 1616692454734,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "jWiuE5X51TkG"
   },
   "outputs": [],
   "source": [
    "net = VGG16Residual()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-syracuse",
   "metadata": {
    "executionInfo": {
     "elapsed": 5107,
     "status": "aborted",
     "timestamp": 1616692454734,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "gBZBvZ6a1Wvv"
   },
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-radiation",
   "metadata": {},
   "source": [
    "### 3.3.2 Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG16Residual()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-detection",
   "metadata": {
    "id": "66C5ftu6cfFP"
   },
   "source": [
    "## 3.4. Dense Net 161 - Residual maps\n",
    "### 3.4.1 Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-wayne",
   "metadata": {
    "executionInfo": {
     "elapsed": 5079,
     "status": "aborted",
     "timestamp": 1616692454737,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "jTX_xhrfZ0wW"
   },
   "outputs": [],
   "source": [
    "net = densenet161()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-maple",
   "metadata": {
    "executionInfo": {
     "elapsed": 5074,
     "status": "aborted",
     "timestamp": 1616692454738,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "gV19-p4jau9u"
   },
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] = accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-effects",
   "metadata": {},
   "source": [
    "### 3.4.2 Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = densenet161()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-defensive",
   "metadata": {
    "executionInfo": {
     "elapsed": 5068,
     "status": "aborted",
     "timestamp": 1616692454738,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "qOcti75Qlfd1"
   },
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-former",
   "metadata": {
    "id": "RFEJTNK8cug8"
   },
   "source": [
    "## 3.5. Google Net - Residual maps\n",
    "### 3.5.1 Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arabic-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GoogLeNet(googlenet(True, True, None,224, dropout_rate=0.2, num_classes=3))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dependent-profile",
   "metadata": {
    "executionInfo": {
     "elapsed": 5058,
     "status": "aborted",
     "timestamp": 1616692454740,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "dLURFuUAfG3a"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6f58448dce9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0maux1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0maux2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplens/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplens/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, aux1, aux2 = net(inputs)\n",
    "        loss = criterion((outputs+aux1+aux2)/3, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs,aux1,aux2 = net(images)\n",
    "            outputs = (outputs+aux1+aux2)/3\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-harbor",
   "metadata": {},
   "source": [
    "### 3.5.2 Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GoogLeNet(googlenet(True, True, None,224, dropout_rate=0.2, num_classes=3))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, aux1, aux2 = net(inputs)\n",
    "        loss = criterion((outputs+aux1+aux2)/3, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs,aux1,aux2 = net(images)\n",
    "            outputs = (outputs+aux1+aux2)/3\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-story",
   "metadata": {
    "id": "FL0p7kKwc0CU"
   },
   "source": [
    "## 3.6. Squeeze Net 1_1  - Residual maps\n",
    "### 3.6.1 Padding\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "romance-lyric",
   "metadata": {
    "executionInfo": {
     "elapsed": 5047,
     "status": "aborted",
     "timestamp": 1616692454741,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "o3gMHYPdfH7C"
   },
   "outputs": [],
   "source": [
    "net = squeezenet1_1()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_pad = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        m = nn.ZeroPad2d(80)\n",
    "        inputs = m(inputs)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            m = nn.ZeroPad2d(80)\n",
    "            images = m(images)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_pad[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-harvey",
   "metadata": {},
   "source": [
    "### 3.6.2 Interpolation\n",
    "**Results** :  epochs -  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = squeezenet1_1()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_int = np.zeros(max_epoch)\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, meta_inputs,labels = data\n",
    "        inputs = F.interpolate(inputs, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    accuracy = 0\n",
    "    iteration = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for data in loader_test:\n",
    "            images, meta_img, labels = data\n",
    "            images = F.interpolate(images, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "            outputs = net(images)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            result = calculate_metrics(np.round(np.array(predictions)), np.array(targets))\n",
    "\n",
    "            accuracy+=result['samples/recall']\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "    test_acc_int[epoch] =accuracy/(iteration+1)\n",
    "\n",
    "    print(\"epoch:{:3d} \\n test:\\n \"\n",
    "            \"accuracy: {:.3f} \".format(epoch, accuracy/(iteration+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_pad, label = 'Padding')\n",
    "sns.lineplot(x=np.arange(0,max_epoch), y=test_acc_int, label = 'Interpolation')\n",
    "# change legend texts\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Accuracy [-]')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
