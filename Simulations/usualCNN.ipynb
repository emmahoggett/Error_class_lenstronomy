{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "metric-chess",
   "metadata": {
    "id": "written-sample"
   },
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifty-oriental",
   "metadata": {
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1616692453475,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "comfortable-tucson"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from helpers import read_hdf5, CombineDataset\n",
    "from lenshelpers import Residual\n",
    "\n",
    "from model.helpers_model import NeuralNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-chancellor",
   "metadata": {
    "id": "enhanced-enterprise"
   },
   "source": [
    "# 1. Building the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "peaceful-detection",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 5231,
     "status": "error",
     "timestamp": 1616692454742,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "intermediate-blood",
    "outputId": "c1d905f2-e341-4469-ac08-4f56582db157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation Finished\n"
     ]
    }
   ],
   "source": [
    "size = 60000\n",
    "ratio = 0.75; percent = 0.01\n",
    "\n",
    "for i in np.arange(1,4):\n",
    "    res = Residual()\n",
    "    res.build(size, i, ratio = ratio, per_error = percent)\n",
    "\n",
    "print('Data Generation Finished')\n",
    "\n",
    "metadata = pd.DataFrame()\n",
    "\n",
    "for i in np.arange(1,4):\n",
    "    ID_images = \"E\"+str(i)+\"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "    [img, meta] = read_hdf5(ID_images, path = \"data/dataSet/\")\n",
    "    metadata = pd.concat([metadata,meta], ignore_index=True)\n",
    "    if i == 1:\n",
    "        final_array = img\n",
    "    else:\n",
    "         final_array = np.concatenate((final_array, img))\n",
    "metadata ['ID'] = np.arange(0,final_array.shape[0])\n",
    "data_set = CombineDataset(metadata,'ID','class',final_array)\n",
    "\n",
    "data_train, data_test = train_test_split(data_set,train_size=0.9,random_state=42)\n",
    "\n",
    "batch_size = 50; max_epoch = 100\n",
    "\n",
    "\n",
    "loader_train = DataLoader(data_train, batch_size = batch_size, \n",
    "                          num_workers = 2, drop_last=True)\n",
    "loader_test = DataLoader(data_test, batch_size = batch_size, \n",
    "                         num_workers = 2, drop_last=True)\n",
    "print('Reading Data Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-digest",
   "metadata": {
    "id": "behind-benchmark"
   },
   "source": [
    "# 2. Neural network\n",
    "## 1. Baseline\n",
    "**Results** : _ epochs - _ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ongoing-footage",
   "metadata": {
    "executionInfo": {
     "elapsed": 5201,
     "status": "aborted",
     "timestamp": 1616692454725,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "UkL0TbTeB092",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epoch: 29.000, auc: 0.859\n",
    "test_acc = np.zeros(max_epoch); \n",
    "netbasic = NeuralNet('BasicCNN', 'Adam')\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "    netbasic.train(loader_train)\n",
    "    res = netbasic.test(loader_test,epoch)\n",
    "\n",
    "netbasic.load_checkpoint()\n",
    "net_name = \"basic_res.pt\"\n",
    "ID_net = \"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "path = \"data/trainedNN/\" \n",
    "torch.save(netbasic.net.state_dict(), path+ID_net+net_name)\n",
    "\n",
    "print('Finished Training - Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-printing",
   "metadata": {},
   "source": [
    "## 2. AlexNet\n",
    "**Results** : _ epochs - _ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ideal-intensity",
   "metadata": {
    "executionInfo": {
     "elapsed": 5190,
     "status": "aborted",
     "timestamp": 1616692454726,
     "user": {
      "displayName": "Emma Hoggett",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPUKVC2O_DRFGM99OSkYdh6iVTYJzQEqnz8pVc7A=s64",
      "userId": "15046273628982635449"
     },
     "user_tz": -60
    },
    "id": "6jdGxSbwAkOV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0.000, auc: 0.564\n",
      "epoch: 26.000, auc: 0.570\n"
     ]
    }
   ],
   "source": [
    "test_acc = np.zeros(max_epoch); \n",
    "# epoch: 10 - accuracy: 0.838\n",
    "netbasic = NeuralNet('AlexNet', 'Adam')\n",
    "netbasic.load_checkpoint()\n",
    "for epoch in range(23,max_epoch):\n",
    "    netbasic.train(loader_train)\n",
    "    res = netbasic.test(loader_test,epoch)\n",
    "    print(str(epoch)+\"\\n\")\n",
    "\n",
    "netbasic.load_checkpoint()\n",
    "net_name = \"alexnet_res.pt\"\n",
    "ID_net = \"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "path = \"data/trainedNN/\" \n",
    "torch.save(netbasic.net.state_dict(), path+ID_net+net_name)\n",
    "   \n",
    "print('Finished Training - AlexNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-forty",
   "metadata": {},
   "source": [
    "## 3. ResNet18\n",
    "**Results** : _ epochs - _ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.zeros(max_epoch);\n",
    "#epoch: 3.000, auc: 0.856\n",
    "netbasic = NeuralNet('ResNet18', 'Adam')\n",
    "for epoch in range(max_epoch):\n",
    "    netbasic.train(loader_train, resize_tp = 'Padding')\n",
    "    res = netbasic.test(loader_test,epoch)\n",
    "    print(str(epoch))\n",
    "netbasic.load_checkpoint()\n",
    "net_name = \"resnet18_res.pt\"\n",
    "ID_net = \"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "path = \"data/trainedNN/\" \n",
    "torch.save(netbasic.net.state_dict(), path+ID_net+net_name)\n",
    "   \n",
    "print('Finished Training - ResNet18')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-opening",
   "metadata": {},
   "source": [
    "## 4. VGG16\n",
    "**Results** : _ epochs - _ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.zeros(max_epoch); \n",
    "netbasic = NeuralNet('VGG16', 'Adam')\n",
    "#epoch: 2.000, auc: 0.845\n",
    "for epoch in range(6,max_epoch):\n",
    "    netbasic.train(loader_train, resize_tp = 'Padding')\n",
    "    res = netbasic.test(loader_test,epoch)\n",
    "    print(str(epoch))\n",
    "\n",
    "netbasic.load_checkpoint()\n",
    "net_name = \"VGG16_res.pt\"\n",
    "ID_net = \"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "path = \"data/trainedNN/\" \n",
    "torch.save(netbasic.net.state_dict(), path+ID_net+net_name)\n",
    "   \n",
    "print('Finished Training - VGG16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-doctrine",
   "metadata": {},
   "source": [
    "## 5. DenseNet161\n",
    "**Results** : _ epochs - _ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.zeros(max_epoch)\n",
    "\n",
    "netbasic = NeuralNet('DenseNet161', 'Adam')\n",
    "for epoch in range(max_epoch):\n",
    "    netbasic.train(loader_train, resize_tp = 'Padding')\n",
    "    res = netbasic.test(loader_test,epoch)\n",
    "    print(str(epoch))\n",
    "\n",
    "netbasic.load_checkpoint()\n",
    "net_name = \"dense121_res.pt\"\n",
    "ID_net = \"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "path = \"data/trainedNN/\" \n",
    "torch.save(netbasic.net.state_dict(), path+ID_net+net_name)\n",
    "   \n",
    "print('Finished Training - DenseNet161')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-point",
   "metadata": {},
   "source": [
    "## 6. GoogleNet\n",
    "**Results** : _ epochs - _ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.zeros(max_epoch)\n",
    "\n",
    "netbasic = NeuralNet('GoogleNet', 'Adam')\n",
    "for epoch in range(max_epoch):\n",
    "    netbasic.train(loader_train, resize_tp = 'Padding')\n",
    "    res = netbasic.test(loader_test,epoch)\n",
    "    print(str(epoch)+\"\\n\")\n",
    "\n",
    "netbasic.load_checkpoint() \n",
    "net_name = \"googleNet_res.pt\"\n",
    "ID_net = \"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "path = \"data/trainedNN/\" \n",
    "torch.save(netbasic.net.state_dict(), path+ID_net+net_name)\n",
    "   \n",
    "print('Finished Training - GoogleNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-partition",
   "metadata": {},
   "source": [
    "## 7. SqueezeNet\n",
    "**Results** : _ epochs - _ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.zeros(max_epoch)\n",
    "\n",
    "netbasic = NeuralNet('SqueezeNet', 'Adam')\n",
    "for epoch in range(max_epoch):\n",
    "    netbasic.train(loader_train, resize_tp = 'Padding')\n",
    "    res = netbasic.test(loader_test,epoch)\n",
    "    print(str(epoch)+\"\\n\")\n",
    "\n",
    "netbasic.load_checkpoint()\n",
    "net_name = \"squeezeNet_res.pt\"\n",
    "ID_net = \"P\"+str(int(percent*100))+\"R\"+str(int(ratio*100))\n",
    "path = \"data/trainedNN/\" \n",
    "torch.save(netbasic.net.state_dict(), path+ID_net+net_name)\n",
    "   \n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
