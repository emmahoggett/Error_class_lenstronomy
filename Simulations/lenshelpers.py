#  this file contains classes that build the residual maps with lenstronomy

import numpy as np
import pandas as pd

from lenstronomy.LensModel.Profiles.pemd import PEMD
from lenstronomy.SimulationAPI.ObservationConfig.HST import HST
from astropy.io import fits
from lenstronomy.SimulationAPI.sim_api import SimAPI

from helpers import store_hdf5
from errors import LensMassError, SourceError

    
class LensDataset:
    """Class that build residual and metadata in lenstronomy. This class """
    def __init__(self, size:int, seed:int = 0, center_x:float = 0, center_y:float = 0, mass_range = None, source_range = None):
        """Initialization of the object LensDataset.
        
        
        :param size: dataset size
        :param seed: random seed for the uniform distribution
        :param center_x: coordinate center of the lens mass profile on the x-axis
        :param center_y: coordinate center of the lens mass profile on the y-axis
        :param param_range: 11x2 matrix, with specified range of the mass and source light profile"""

        
        psf_hdu = fits.open('data/psf.fits')
        kwargs_hst = HST().kwargs_single_band()
        kwargs_hst['kernel_point_source'] = np.array(psf_hdu[0].data)
        numPix = 64 

        kwargs_model = {'lens_model_list': ['PEMD'],        # list of lens models to be used
                        'source_light_model_list': ['SERSIC_ELLIPSE'],  # list of extended source models to be used
            }
        self.size = size
        self.image_config = SimAPI(numpix=numPix, kwargs_single_band=kwargs_hst, kwargs_model=kwargs_model)
        self.img_sim = self.image_config.image_model_class()
        
        
        # Build dictionnary
        self.mass_error = LensMassError(size,seed, center_x, center_y, mass_range)
        self.source_error = SourceError(size,seed,source_range)
        
        self.metadata = pd.concat([self.mass_error.metadata,self.source_error.metadata], axis =1)
        self.images = np.zeros((self.size, 1,64,64))
        
        for i in np.arange(0,self.size): 
            kwargs_lens = self.mass_error.get_kwargs(i)
            kwargs_source = self.source_error.get_kwargs(i)

            # generate image
            self.images[i,:,:] = self.img_sim.image(kwargs_lens, kwargs_source, kwargs_ps=None)
        
    
class  Residual:
    """
    Class that build the residual maps and the metadata. This dataset ends up in the folder data/dataSet by default.
    The data set is generated by the lenstronomy simulators.
    
    The file ID is coded as following : E[error_number]P[percent_error]R[ratio]_lens.h5 for the residual maps and 
    E[error_number]P[percent_error]R[ratio]_meta.h5 for the metadata.
    """

    def build(self, size:int, errorID:int, ratio:float = 0.75, per_error:float = 0.01, num_class:int = 3, center_x:float = 0, center_y:float = 0,
              mass_range = None, source_range = None, path_data:str = "data/dataSet/"):
        """
        
        :param size         : int, size of the 
        :param errorID      : int, 
        :param ratio        : float, ratio between true and false residuals maps
        :param per_error    : float, percentage of error between observed data and 
        :param num_class    : int, number of classes
        :param center_x     : float, x-position of the lens center - default : 0
        :param center_y     : float, y-position of the lens center - default : 0
        :param mass_range   : np.array (4,2), array that contain the distribution parameters of each configuration in the following order :
                    - theta_E : Einstein radius(angle), log-normal distribution [mu,sigma]- default : N(0,0.1)
                    - gamma   : Logarithmic slope of the power-law profile, log-normal distribution [mu,sigma]- default : N(0.7,0.1)
                    - q       : Axis ratio, uniform distribution [a,b] - default : U(0.7,1)
                    - phi     : Position angle, uniform distribution [a,b] - default : U(0,pi/2)
        :param source_range : np.array (7,2), array that contain the distribution parameters of each source configurationin the following order :
                - amp      : Surface brightness/amplitude value at the half light radius, uniform distribution [a,b] - default : U(20,24)
                - R        : Semi-major axis half light radius, log-normal distribution [mu,sigma]- default : N(-0.7,0.4)
                - n        : Sersic index, log-normal distribution [mu,sigma]- default : N(0.7,0.4)
                - center_x : x-position of the source center, uniform distribution [a,b] - default : U(-0.5,0.5)
                - center_y : y-position of the source center, uniform distribution [a,b] - default : U(-0.5,0.5)
                - q        : Axis ratio, uniform distribution [a,b] - default : U(0.7,1)
                - phi      : Position angle, uniform distribution [a,b] - default : U(0,pi/2)
        :param path_data    : str, 
        """
        
        self.size = round(size/num_class)
        dataset_model = LensDataset(size = size, center_x = center_x, center_y = center_y, mass_range = mass_range, source_range= source_range)
        self.path_data = path_data

        self.channels = dataset_model.images.shape[1]
        metadata = pd.DataFrame()
        residuals = np.zeros((self.size, self.channels,64,64))
        bool_mdimg = np.array([], dtype='int')
        k = 0
        
        # generate residual maps where the model match the observed strong lens
        true_idx = np.array([], dtype='int')
        np.random.seed(errorID*10)
        
        while true_idx.shape[0]<((1-ratio)*self.size):
            r=np.random.randint(0,size-1)
            if r not in true_idx: true_idx = np.append(true_idx, r)
                
        for i in true_idx:
            metadata_temp = dataset_model.metadata.take([i])
            img_test = np.zeros((1, self.channels,64,64))
            
            for i_ch in np.arange(0,self.channels):
                image_model = dataset_model.images[i][i_ch]
                image_real = dataset_model.images[i][i_ch] + dataset_model.image_config.noise_for_model(model = dataset_model.images[i][i_ch])
                sigma = np.sqrt(dataset_model.img_sim.Data.C_D_model(model = dataset_model.images[i][i_ch]))
                residuals[k,i_ch,:,:] = (image_real-image_model)/sigma
                
            bool_mdimg = np.concatenate((bool_mdimg, np.array([1,0,0])))
            metadata = pd.concat([metadata,dataset_model.metadata.take([i])])
            k = k+1
        
        # generate residual maps where the model doesn't match the observed strong lens
        false_idx = np.array([], dtype='int')
        np.random.seed(errorID*10)
        
        while false_idx.shape[0]<(self.size-true_idx.shape[0]):
            r=np.random.randint(0,size-1)
            if r not in false_idx: false_idx = np.append(false_idx, r)

        img_test = np.zeros((self.channels,64,64))  
        for i in false_idx:
            kwargs_lens = dataset_model.mass_error.add_error(i,per_error)
            kwargs_source = dataset_model.source_error.add_error(i,per_error)
            error = dataset_model.mass_error.type_error + dataset_model.source_error.type_error
            if errorID == 1:
                kwargs_source = dataset_model.source_error.get_kwargs(i)
                error = dataset_model.mass_error.type_error
            elif errorID == 2:
                kwargs_lens = dataset_model.mass_error.get_kwargs(i)
                error = dataset_model.source_error.type_error
            img_test = dataset_model.img_sim.image(kwargs_lens, kwargs_source, kwargs_ps=None)
            
            for i_ch in np.arange(0,self.channels):
                image_model = dataset_model.images[i][i_ch]
                image_real = img_test + dataset_model.image_config.noise_for_model(model = img_test)
                sigma = np.sqrt(dataset_model.img_sim.Data.C_D_model(model = img_test))
                residuals[k,i_ch,:,:] = (image_real-image_model)/sigma
            bool_mdimg = np.concatenate((bool_mdimg, error))
            metadata = pd.concat([metadata,dataset_model.metadata.take([i])])
            k = k+1
            
        # Add the labels for each model and store the dataset in .h5 file
        metadata['class'] = np.reshape(bool_mdimg, (-1, 3)).tolist()
        self.residuals = residuals; self.metadata = metadata
        ID_img = "E"+str(errorID)+"P"+str(int(per_error*100))+"R"+str(int(ratio*100))
        store_hdf5(residuals, metadata, ID_img, path = self.path_data)
